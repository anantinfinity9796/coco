{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import os\n",
    "import imageio \n",
    "from plotly.subplots import make_subplots\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, Resize\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "# from pytorch_model_summary import summary\n",
    "torch.random.manual_seed(42)\n",
    "from mlcm import mlcm\n",
    "import ipdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA GeForce GTX 1050 Ti', major=6, minor=1, total_memory=4096MB, multi_processor_count=6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.get_device_properties(device = 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Reading the image and the captions dataframe and the labels dataframe which has the super categories.\n",
    "image_df = pd.read_csv('F://coco/captions/final_captions.csv',)\n",
    "labels_df = pd.read_csv('F://coco/captions/labels_information_full.csv')\n",
    "\n",
    "# Also we need to read the multilabel dataframe which has the multilabel infomration about the images.\n",
    "multilabel_df = pd.read_csv('F://coco/captions/multilabel_labels.csv').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>food</th>\n",
       "      <th>animal</th>\n",
       "      <th>furniture</th>\n",
       "      <th>electronic</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>person</th>\n",
       "      <th>outdoor</th>\n",
       "      <th>accessory</th>\n",
       "      <th>sports</th>\n",
       "      <th>appliance</th>\n",
       "      <th>indoor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57870</td>\n",
       "      <td>COCO_train2014_000000057870.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>384029</td>\n",
       "      <td>COCO_train2014_000000384029.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222016</td>\n",
       "      <td>COCO_train2014_000000222016.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>520950</td>\n",
       "      <td>COCO_train2014_000000520950.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69675</td>\n",
       "      <td>COCO_train2014_000000069675.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66809</th>\n",
       "      <td>360271</td>\n",
       "      <td>COCO_train2014_000000360271.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66810</th>\n",
       "      <td>471345</td>\n",
       "      <td>COCO_train2014_000000471345.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66811</th>\n",
       "      <td>444010</td>\n",
       "      <td>COCO_train2014_000000444010.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66812</th>\n",
       "      <td>565004</td>\n",
       "      <td>COCO_train2014_000000565004.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66813</th>\n",
       "      <td>516168</td>\n",
       "      <td>COCO_train2014_000000516168.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66814 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                        file_name  food  animal  furniture  \\\n",
       "0         57870  COCO_train2014_000000057870.jpg   0.0     0.0        1.0   \n",
       "1        384029  COCO_train2014_000000384029.jpg   1.0     0.0        0.0   \n",
       "2        222016  COCO_train2014_000000222016.jpg   0.0     0.0        0.0   \n",
       "3        520950  COCO_train2014_000000520950.jpg   0.0     0.0        0.0   \n",
       "4         69675  COCO_train2014_000000069675.jpg   0.0     0.0        0.0   \n",
       "...         ...                              ...   ...     ...        ...   \n",
       "66809    360271  COCO_train2014_000000360271.jpg   0.0     0.0        1.0   \n",
       "66810    471345  COCO_train2014_000000471345.jpg   1.0     0.0        1.0   \n",
       "66811    444010  COCO_train2014_000000444010.jpg   1.0     0.0        1.0   \n",
       "66812    565004  COCO_train2014_000000565004.jpg   0.0     0.0        1.0   \n",
       "66813    516168  COCO_train2014_000000516168.jpg   0.0     0.0        1.0   \n",
       "\n",
       "       electronic  kitchen  vehicle  person  outdoor  accessory  sports  \\\n",
       "0             0.0      0.0      0.0     0.0      0.0        0.0     0.0   \n",
       "1             0.0      0.0      0.0     1.0      0.0        0.0     0.0   \n",
       "2             0.0      0.0      0.0     1.0      0.0        0.0     0.0   \n",
       "3             0.0      1.0      0.0     0.0      0.0        0.0     0.0   \n",
       "4             0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "...           ...      ...      ...     ...      ...        ...     ...   \n",
       "66809         0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "66810         0.0      1.0      0.0     0.0      0.0        0.0     0.0   \n",
       "66811         0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "66812         0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "66813         0.0      1.0      0.0     1.0      0.0        1.0     0.0   \n",
       "\n",
       "       appliance  indoor  \n",
       "0            0.0     1.0  \n",
       "1            0.0     0.0  \n",
       "2            0.0     0.0  \n",
       "3            1.0     0.0  \n",
       "4            1.0     0.0  \n",
       "...          ...     ...  \n",
       "66809        0.0     0.0  \n",
       "66810        0.0     0.0  \n",
       "66811        0.0     0.0  \n",
       "66812        0.0     0.0  \n",
       "66813        0.0     1.0  \n",
       "\n",
       "[66814 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_label_df = image_df[['image_id','file_name']].merge(multilabel_df, on='image_id',validate='1:1')\n",
    "image_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_channel_list = ['COCO_train2014_000000061048.jpg',\n",
    "'COCO_train2014_000000434765.jpg',\n",
    "'COCO_train2014_000000053756.jpg',\n",
    "'COCO_train2014_000000470933.jpg',\n",
    "'COCO_train2014_000000571415.jpg',\n",
    "'COCO_train2014_000000492325.jpg',\n",
    "'COCO_train2014_000000155083.jpg',\n",
    "'COCO_train2014_000000421613.jpg',\n",
    "'COCO_train2014_000000431115.jpg',\n",
    "'COCO_train2014_000000173610.jpg',\n",
    "'COCO_train2014_000000336668.jpg',\n",
    "'COCO_train2014_000000316867.jpg',\n",
    "'COCO_train2014_000000269858.jpg',\n",
    "'COCO_train2014_000000250239.jpg',\n",
    "'COCO_train2014_000000123539.jpg',\n",
    "'COCO_train2014_000000140092.jpg',\n",
    "'COCO_train2014_000000343009.jpg',\n",
    "'COCO_train2014_000000003293.jpg',\n",
    "'COCO_train2014_000000578250.jpg',\n",
    "'COCO_train2014_000000518025.jpg',\n",
    "'COCO_train2014_000000008794.jpg',\n",
    "'COCO_train2014_000000400107.jpg',\n",
    "'COCO_train2014_000000394547.jpg',\n",
    "'COCO_train2014_000000389984.jpg',\n",
    "'COCO_train2014_000000225717.jpg',\n",
    "'COCO_train2014_000000032405.jpg',\n",
    "'COCO_train2014_000000084582.jpg',\n",
    "'COCO_train2014_000000549879.jpg',\n",
    "'COCO_train2014_000000358281.jpg',\n",
    "'COCO_train2014_000000457741.jpg',\n",
    "'COCO_train2014_000000204792.jpg',\n",
    "'COCO_train2014_000000124694.jpg',\n",
    "'COCO_train2014_000000390663.jpg',\n",
    "'COCO_train2014_000000179405.jpg',\n",
    "'COCO_train2014_000000443909.jpg',\n",
    "'COCO_train2014_000000268036.jpg',\n",
    "'COCO_train2014_000000217341.jpg',\n",
    "'COCO_train2014_000000363331.jpg',\n",
    "'COCO_train2014_000000134071.jpg',\n",
    "'COCO_train2014_000000505962.jpg',\n",
    "'COCO_train2014_000000347111.jpg',\n",
    "'COCO_train2014_000000484742.jpg',\n",
    "'COCO_train2014_000000064270.jpg',\n",
    "'COCO_train2014_000000012345.jpg',\n",
    "'COCO_train2014_000000226585.jpg',\n",
    "'COCO_train2014_000000575029.jpg',\n",
    "'COCO_train2014_000000564314.jpg',\n",
    "'COCO_train2014_000000011801.jpg',\n",
    "'COCO_train2014_000000033127.jpg',\n",
    "'COCO_train2014_000000312288.jpg',\n",
    "'COCO_train2014_000000126531.jpg',\n",
    "'COCO_train2014_000000140627.jpg',\n",
    "'COCO_train2014_000000131366.jpg',\n",
    "'COCO_train2014_000000406011.jpg',\n",
    "'COCO_train2014_000000369966.jpg',\n",
    "'COCO_train2014_000000081003.jpg',\n",
    "'COCO_train2014_000000010125.jpg',\n",
    "'COCO_train2014_000000006432.jpg',\n",
    "'COCO_train2014_000000384693.jpg',\n",
    "'COCO_train2014_000000470442.jpg',\n",
    "'COCO_train2014_000000280731.jpg',\n",
    "'COCO_train2014_000000113929.jpg',\n",
    "'COCO_train2014_000000416869.jpg',\n",
    "'COCO_train2014_000000066642.jpg',\n",
    "'COCO_train2014_000000233263.jpg',\n",
    "'COCO_train2014_000000025404.jpg',\n",
    "'COCO_train2014_000000156878.jpg',\n",
    "'COCO_train2014_000000166522.jpg',\n",
    "'COCO_train2014_000000060060.jpg',\n",
    "'COCO_train2014_000000445845.jpg',\n",
    "'COCO_train2014_000000205486.jpg',\n",
    "'COCO_train2014_000000577207.jpg',\n",
    "'COCO_train2014_000000005294.jpg',\n",
    "'COCO_train2014_000000186888.jpg',\n",
    "'COCO_train2014_000000503640.jpg',\n",
    "'COCO_train2014_000000000086.jpg',\n",
    "'COCO_train2014_000000087509.jpg',\n",
    "'COCO_train2014_000000571503.jpg',\n",
    "'COCO_train2014_000000000821.jpg',\n",
    "'COCO_train2014_000000579138.jpg',\n",
    "'COCO_train2014_000000134918.jpg',\n",
    "'COCO_train2014_000000259284.jpg',\n",
    "'COCO_train2014_000000257178.jpg',\n",
    "'COCO_train2014_000000221691.jpg',\n",
    "'COCO_train2014_000000077709.jpg',\n",
    "'COCO_train2014_000000263002.jpg',\n",
    "'COCO_train2014_000000341892.jpg',\n",
    "'COCO_train2014_000000349069.jpg',\n",
    "'COCO_train2014_000000563376.jpg',\n",
    "'COCO_train2014_000000220770.jpg',\n",
    "'COCO_train2014_000000208206.jpg',\n",
    "'COCO_train2014_000000027412.jpg',\n",
    "'COCO_train2014_000000434837.jpg',\n",
    "'COCO_train2014_000000080906.jpg',\n",
    "'COCO_train2014_000000150354.jpg',\n",
    "'COCO_train2014_000000107450.jpg',\n",
    "'COCO_train2014_000000577265.jpg',\n",
    "'COCO_train2014_000000416372.jpg',\n",
    "'COCO_train2014_000000377837.jpg',\n",
    "'COCO_train2014_000000579239.jpg',\n",
    "'COCO_train2014_000000540378.jpg',\n",
    "'COCO_train2014_000000525513.jpg',\n",
    "'COCO_train2014_000000353952.jpg',\n",
    "'COCO_train2014_000000006379.jpg',\n",
    "'COCO_train2014_000000381270.jpg',\n",
    "'COCO_train2014_000000520479.jpg',\n",
    "'COCO_train2014_000000563447.jpg',\n",
    "'COCO_train2014_000000085407.jpg',\n",
    "'COCO_train2014_000000210175.jpg',\n",
    "'COCO_train2014_000000397575.jpg',\n",
    "'COCO_train2014_000000058517.jpg',\n",
    "'COCO_train2014_000000384907.jpg',\n",
    "'COCO_train2014_000000509358.jpg',\n",
    "'COCO_train2014_000000264165.jpg',\n",
    "'COCO_train2014_000000072098.jpg',\n",
    "'COCO_train2014_000000155954.jpg',\n",
    "'COCO_train2014_000000270925.jpg',\n",
    "'COCO_train2014_000000104124.jpg',\n",
    "'COCO_train2014_000000095753.jpg',\n",
    "'COCO_train2014_000000210847.jpg',\n",
    "'COCO_train2014_000000507794.jpg',\n",
    "'COCO_train2014_000000561842.jpg',\n",
    "'COCO_train2014_000000249835.jpg',\n",
    "'COCO_train2014_000000361516.jpg',\n",
    "'COCO_train2014_000000451074.jpg',\n",
    "'COCO_train2014_000000480482.jpg',\n",
    "'COCO_train2014_000000220898.jpg',\n",
    "'COCO_train2014_000000260962.jpg',\n",
    "'COCO_train2014_000000576700.jpg',\n",
    "'COCO_train2014_000000296884.jpg',\n",
    "'COCO_train2014_000000342921.jpg',\n",
    "'COCO_train2014_000000384910.jpg',\n",
    "'COCO_train2014_000000040428.jpg',\n",
    "'COCO_train2014_000000145288.jpg',\n",
    "'COCO_train2014_000000321897.jpg',\n",
    "'COCO_train2014_000000449901.jpg',\n",
    "'COCO_train2014_000000107962.jpg',\n",
    "'COCO_train2014_000000001350.jpg',\n",
    "'COCO_train2014_000000249711.jpg',\n",
    "'COCO_train2014_000000140623.jpg',\n",
    "'COCO_train2014_000000211867.jpg',\n",
    "'COCO_train2014_000000496444.jpg',\n",
    "'COCO_train2014_000000287422.jpg',\n",
    "'COCO_train2014_000000118895.jpg',\n",
    "'COCO_train2014_000000075052.jpg',\n",
    "'COCO_train2014_000000436984.jpg',\n",
    "'COCO_train2014_000000555583.jpg',\n",
    "'COCO_train2014_000000029275.jpg',\n",
    "'COCO_train2014_000000176397.jpg',\n",
    "'COCO_train2014_000000034861.jpg',\n",
    "'COCO_train2014_000000517899.jpg',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for file_name in single_channel_list:\n",
    "    index = image_label_df[image_label_df['file_name']==file_name].index.values[0]\n",
    "    indexes.append(index)\n",
    "    # print(index)\n",
    "    # image_label_df.drop(, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>food</th>\n",
       "      <th>animal</th>\n",
       "      <th>furniture</th>\n",
       "      <th>electronic</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>person</th>\n",
       "      <th>outdoor</th>\n",
       "      <th>accessory</th>\n",
       "      <th>sports</th>\n",
       "      <th>appliance</th>\n",
       "      <th>indoor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57870</td>\n",
       "      <td>COCO_train2014_000000057870.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>384029</td>\n",
       "      <td>COCO_train2014_000000384029.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222016</td>\n",
       "      <td>COCO_train2014_000000222016.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>520950</td>\n",
       "      <td>COCO_train2014_000000520950.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69675</td>\n",
       "      <td>COCO_train2014_000000069675.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66809</th>\n",
       "      <td>360271</td>\n",
       "      <td>COCO_train2014_000000360271.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66810</th>\n",
       "      <td>471345</td>\n",
       "      <td>COCO_train2014_000000471345.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66811</th>\n",
       "      <td>444010</td>\n",
       "      <td>COCO_train2014_000000444010.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66812</th>\n",
       "      <td>565004</td>\n",
       "      <td>COCO_train2014_000000565004.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66813</th>\n",
       "      <td>516168</td>\n",
       "      <td>COCO_train2014_000000516168.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66814 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                        file_name  food  animal  furniture  \\\n",
       "0         57870  COCO_train2014_000000057870.jpg   0.0     0.0        1.0   \n",
       "1        384029  COCO_train2014_000000384029.jpg   1.0     0.0        0.0   \n",
       "2        222016  COCO_train2014_000000222016.jpg   0.0     0.0        0.0   \n",
       "3        520950  COCO_train2014_000000520950.jpg   0.0     0.0        0.0   \n",
       "4         69675  COCO_train2014_000000069675.jpg   0.0     0.0        0.0   \n",
       "...         ...                              ...   ...     ...        ...   \n",
       "66809    360271  COCO_train2014_000000360271.jpg   0.0     0.0        1.0   \n",
       "66810    471345  COCO_train2014_000000471345.jpg   1.0     0.0        1.0   \n",
       "66811    444010  COCO_train2014_000000444010.jpg   1.0     0.0        1.0   \n",
       "66812    565004  COCO_train2014_000000565004.jpg   0.0     0.0        1.0   \n",
       "66813    516168  COCO_train2014_000000516168.jpg   0.0     0.0        1.0   \n",
       "\n",
       "       electronic  kitchen  vehicle  person  outdoor  accessory  sports  \\\n",
       "0             0.0      0.0      0.0     0.0      0.0        0.0     0.0   \n",
       "1             0.0      0.0      0.0     1.0      0.0        0.0     0.0   \n",
       "2             0.0      0.0      0.0     1.0      0.0        0.0     0.0   \n",
       "3             0.0      1.0      0.0     0.0      0.0        0.0     0.0   \n",
       "4             0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "...           ...      ...      ...     ...      ...        ...     ...   \n",
       "66809         0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "66810         0.0      1.0      0.0     0.0      0.0        0.0     0.0   \n",
       "66811         0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "66812         0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "66813         0.0      1.0      0.0     1.0      0.0        1.0     0.0   \n",
       "\n",
       "       appliance  indoor  \n",
       "0            0.0     1.0  \n",
       "1            0.0     0.0  \n",
       "2            0.0     0.0  \n",
       "3            1.0     0.0  \n",
       "4            1.0     0.0  \n",
       "...          ...     ...  \n",
       "66809        0.0     0.0  \n",
       "66810        0.0     0.0  \n",
       "66811        0.0     0.0  \n",
       "66812        0.0     0.0  \n",
       "66813        0.0     1.0  \n",
       "\n",
       "[66814 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>food</th>\n",
       "      <th>animal</th>\n",
       "      <th>furniture</th>\n",
       "      <th>electronic</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>person</th>\n",
       "      <th>outdoor</th>\n",
       "      <th>accessory</th>\n",
       "      <th>sports</th>\n",
       "      <th>appliance</th>\n",
       "      <th>indoor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57870</td>\n",
       "      <td>COCO_train2014_000000057870.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>384029</td>\n",
       "      <td>COCO_train2014_000000384029.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222016</td>\n",
       "      <td>COCO_train2014_000000222016.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>520950</td>\n",
       "      <td>COCO_train2014_000000520950.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69675</td>\n",
       "      <td>COCO_train2014_000000069675.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66658</th>\n",
       "      <td>360271</td>\n",
       "      <td>COCO_train2014_000000360271.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66659</th>\n",
       "      <td>471345</td>\n",
       "      <td>COCO_train2014_000000471345.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66660</th>\n",
       "      <td>444010</td>\n",
       "      <td>COCO_train2014_000000444010.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66661</th>\n",
       "      <td>565004</td>\n",
       "      <td>COCO_train2014_000000565004.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66662</th>\n",
       "      <td>516168</td>\n",
       "      <td>COCO_train2014_000000516168.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66663 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                        file_name  food  animal  furniture  \\\n",
       "0         57870  COCO_train2014_000000057870.jpg   0.0     0.0        1.0   \n",
       "1        384029  COCO_train2014_000000384029.jpg   1.0     0.0        0.0   \n",
       "2        222016  COCO_train2014_000000222016.jpg   0.0     0.0        0.0   \n",
       "3        520950  COCO_train2014_000000520950.jpg   0.0     0.0        0.0   \n",
       "4         69675  COCO_train2014_000000069675.jpg   0.0     0.0        0.0   \n",
       "...         ...                              ...   ...     ...        ...   \n",
       "66658    360271  COCO_train2014_000000360271.jpg   0.0     0.0        1.0   \n",
       "66659    471345  COCO_train2014_000000471345.jpg   1.0     0.0        1.0   \n",
       "66660    444010  COCO_train2014_000000444010.jpg   1.0     0.0        1.0   \n",
       "66661    565004  COCO_train2014_000000565004.jpg   0.0     0.0        1.0   \n",
       "66662    516168  COCO_train2014_000000516168.jpg   0.0     0.0        1.0   \n",
       "\n",
       "       electronic  kitchen  vehicle  person  outdoor  accessory  sports  \\\n",
       "0             0.0      0.0      0.0     0.0      0.0        0.0     0.0   \n",
       "1             0.0      0.0      0.0     1.0      0.0        0.0     0.0   \n",
       "2             0.0      0.0      0.0     1.0      0.0        0.0     0.0   \n",
       "3             0.0      1.0      0.0     0.0      0.0        0.0     0.0   \n",
       "4             0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "...           ...      ...      ...     ...      ...        ...     ...   \n",
       "66658         0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "66659         0.0      1.0      0.0     0.0      0.0        0.0     0.0   \n",
       "66660         0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "66661         0.0      1.0      0.0     1.0      0.0        0.0     0.0   \n",
       "66662         0.0      1.0      0.0     1.0      0.0        1.0     0.0   \n",
       "\n",
       "       appliance  indoor  \n",
       "0            0.0     1.0  \n",
       "1            0.0     0.0  \n",
       "2            0.0     0.0  \n",
       "3            1.0     0.0  \n",
       "4            1.0     0.0  \n",
       "...          ...     ...  \n",
       "66658        0.0     0.0  \n",
       "66659        0.0     0.0  \n",
       "66660        0.0     0.0  \n",
       "66661        0.0     0.0  \n",
       "66662        0.0     1.0  \n",
       "\n",
       "[66663 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_label_df = image_label_df.drop(indexes, axis = 0)\n",
    "image_label_df = image_label_df.reset_index(drop=True)\n",
    "image_label_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we we have modified the data to suit our needs. Next we will start to focus on creating the dataset out of the data and the model.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(Dataset):\n",
    "    def __init__(self,image_label_df, val_stride = 10, is_val_set_bool = False, test_data_set =False, test_stride = 5):\n",
    "        \n",
    "        self.transfrom = Resize((224,224))\n",
    "        self.is_val_set_bool = is_val_set_bool\n",
    "        self.val_stride = val_stride\n",
    "        self.image_label_df = image_label_df.copy()\n",
    "        self.test_data_set = test_data_set\n",
    "        self.test_stride = test_stride\n",
    "\n",
    "        if self.test_data_set: #If we need only a small subset of the data to work with\n",
    "            self.image_label_df = self.image_label_df[::test_stride].reset_index(drop = True)\n",
    "\n",
    "        elif self.is_val_set_bool: # If we need only the validation data then return the validation data which is a subset of total data\n",
    "            assert self.val_stride > 0\n",
    "            self.image_label_df = self.image_label_df[::val_stride]\n",
    "\n",
    "        elif self.val_stride > 0:  # Else if val_stride is greater than zero then return the remaining dataframe after removing 10% of data\n",
    "            self.image_label_df = self.image_label_df.drop(index = list(range(0,len(self.image_label_df),self.val_stride)))\n",
    "            \n",
    "        else: # else train on the full dataset\n",
    "            self.image_label_df = self.image_label_df\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\" This method calculates the length of your data.\"\"\"\n",
    "        return len(self.image_label_df)\n",
    "\n",
    "    # Now we will introduce function which gives us an image and its corresponding labels by id\n",
    "    def get_image_by_id(self, img_id = None):\n",
    "        \"\"\" This function returns an image by its id and the corresponding multiple labesl in a present/no_present binary format\"\"\"\n",
    "        \n",
    "\n",
    "        folder_path = 'F://coco/train2014/train2014/'\n",
    "\n",
    "        if img_id == None:\n",
    "            raise ValueError('Must provide IMAGE ID')\n",
    "\n",
    "        else:\n",
    "            row = self.image_label_df[self.image_label_df['image_id']==img_id]\n",
    "            file_name = row['file_name'].values[0]\n",
    "\n",
    "            \n",
    "            label_array = torch.zeros(len(multilabel_df.columns[1:]),2)  # create an array of zeros which is a (num_classes, 2) array\n",
    "\n",
    "            # Lets get the multilabel array for a particular image_id from multilabel_df\n",
    "            multilabel_array = row.values[0][2:]\n",
    "\n",
    "            # Now lets populate the label_array with values from the multilabel array\n",
    "            label_array[range(len(multilabel_array)), multilabel_array] = 1\n",
    "\n",
    "            # Get the image-data from file_name\n",
    "            image_array = torchvision.io.read_image(folder_path + file_name)\n",
    "            image_array = self.transfrom(image_array).to(torch.float32)\n",
    "        \n",
    "            return image_array, label_array\n",
    "\n",
    "\n",
    "    # Now we would write the code for returning the image from index and its corresponding labels. Which would be used by the train/val dataloaders\n",
    "    def __getitem__(self, ndx):\n",
    "\n",
    "        \"\"\" This function takes in an index and returns the image and the labels of the image at that index\"\"\"\n",
    "        folder_path = 'F://coco/train2014/train2014/'\n",
    "        \n",
    "        row = self.image_label_df.iloc[ndx]\n",
    "\n",
    "        # Now get the image_id and the file_name of the image\n",
    "        image_id = row['image_id']\n",
    "        file_name = row['file_name']\n",
    "\n",
    "        # print(image_id, file_name)\n",
    "        # Now get the multilabel in the form of a numpy array\n",
    "        # This array would be of the shape (num_classes, 2). Which means that if a class is present or not present and we will keep 1 at that\n",
    "        # Input probabilities for each class wo\n",
    "        label_array = torch.zeros(len(self.image_label_df.columns[2:]),2)  # create an array of zeros which is a (num_classes, 2) array\n",
    "\n",
    "\n",
    "        # Now we will use the multiple_labels array to populate the categories which are present in the picture.\n",
    "        # For each category we will populate 1 at the 0th position if it is not present or 1 at the 1th position if it is present\n",
    "        # This way we can check for the prescence or absence of multiple categories which makes it a multilabel classification problem\n",
    "\n",
    "        \n",
    "\n",
    "        # Lets get the multilabel array for a particular image_id\n",
    "        multilabel_array = row.values[2:].astype(np.float32)\n",
    "\n",
    "        # Now lets populate the label_array with values from the multilabel array\n",
    "        label_array[range(len(multilabel_array)), multilabel_array] = 1\n",
    "\n",
    "        # Now get the image_data from storage\n",
    "        image_array = torchvision.io.read_image(folder_path + file_name)\n",
    "        image_array = self.transfrom(image_array).to(torch.float32)\n",
    "        return (image_array, label_array, image_id)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coco = CocoDataset(image_label_df=image_label_df, test_data_set=True, test_stride=5)\n",
    "# img, labels, id = coco[3]\n",
    "# print(img.shape, labels.shape)\n",
    "# px.imshow(img.permute(1,2,0).numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the train and val dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coco = CocoDataset(image_label_df=image_label_df, val_stride=5)\n",
    "val_coco = CocoDataset(image_label_df=image_label_df,is_val_set_bool=True)\n",
    "\n",
    "# train_dataloader = DataLoader(dataset=train_coco, batch_size=128, pin_memory=True, drop_last=True)\n",
    "# val_dataloader = DataLoader(dataset=val_coco, batch_size=128,pin_memory=True, drop_last = True)\n",
    "\n",
    "# test_coco = CocoDataset(image_label_df=image_label_df, test_data_set=True, test_stride=50)\n",
    "\n",
    "# test_coco_dataloader = DataLoader(dataset=test_coco, batch_size=128, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53330"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 128, 128]) torch.Size([128, 12, 2])\n"
     ]
    }
   ],
   "source": [
    "for image, label, id in train_dataloader:\n",
    "    print(image.shape, label.shape )\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model for predicting the classes\n",
    "* Sequential ConvNet :\n",
    "    1. First we will create a simple Convnet model which would predict the mutiple classes and train the network.\n",
    "    2. This would have 5 Convolution layers and fully connected layers.\n",
    "    3. It would also have 12 heads which would predict the presence or absence of the 12 classes in the coco dataset.\n",
    "    4. Each head would have a binary crossentropy loss as the metric and we would average the losses of all the heads to get the final loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqConvnet(nn.Module):\n",
    "    def __init__(self, n_chan = 64):\n",
    "        super().__init__()\n",
    "\n",
    "        # First we will put channels in the n_chan variable\n",
    "        self.n_chan = n_chan\n",
    "        # Now we would define the first convlution layer which would take in a (B,N,H,w) tensor of images as input and perform convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels=n_chan, kernel_size=3,padding='same') # in_shape = (32,3,400,400) | out_shape = (32,64,400,400)\n",
    "        # A maxpool and a relu \n",
    "        self.max_pool1 = nn.MaxPool2d(2)\n",
    "        # self.tanh1 = nn.Tanh()\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels = n_chan, out_channels = n_chan//2, kernel_size= 3, padding = 'same') # shape = (32,64,200,200) | out_shape = (32,32,200,200)\n",
    "        # A maxpool and a relu \n",
    "        self.max_pool2 = nn.MaxPool2d(2)\n",
    "        # self.tanh2 = nn.Tanh()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels = n_chan//2, out_channels=n_chan//4, kernel_size=3, padding='same') # shape = (32,32,200,200) | out_shape = (32,16,100,100)\n",
    "        # A maxpool and a relu \n",
    "        self.max_pool3 = nn.MaxPool2d(2)\n",
    "        # self.tanh3 = nn.Tanh()\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels = n_chan//4, out_channels=n_chan//8, kernel_size=3, padding='same') # shape = (32,16,50,50) | out_shape = (32,8,50,50)\n",
    "        self.max_pool4 = nn.MaxPool2d(2) # shape = (32,8,50,50) | out_shape = (32,8,25,25)\n",
    "        # self.tanh4 = nn.Tanh()\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        # Now we will define the fully connected layers\n",
    "        self.fc1 = nn.Linear((n_chan//8)*8*8, 4096) # in_shape = (32,160000) | out_shape = (32,1024)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(4096)\n",
    "        # self.tanh5 = nn.Tanh()\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(4096,1024) # in_shape = (32,1024) | out_shape = (32,256)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(1024)\n",
    "        # self.tanh6 = nn.Tanh()\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(1024, 128) # in_shape = (32,256) | out_shape = (32,128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(128)\n",
    "        # self.tanh7 = nn.Tanh()\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.head1 = nn.Linear(128,2)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.head2 = nn.Linear(128,2)\n",
    "        self.sig2 = nn.Sigmoid()\n",
    "        self.head3 = nn.Linear(128,2)\n",
    "        self.sig3 = nn.Sigmoid()\n",
    "        self.head4 = nn.Linear(128,2)\n",
    "        self.sig4 = nn.Sigmoid()\n",
    "        self.head5 = nn.Linear(128,2)\n",
    "        self.sig5 = nn.Sigmoid()\n",
    "        self.head6 = nn.Linear(128,2)\n",
    "        self.sig6 = nn.Sigmoid()\n",
    "        self.head7 = nn.Linear(128,2)\n",
    "        self.sig7 = nn.Sigmoid()\n",
    "        self.head8 = nn.Linear(128,2)\n",
    "        self.sig8 = nn.Sigmoid()\n",
    "        self.head9 = nn.Linear(128,2)\n",
    "        self.sig9 = nn.Sigmoid()\n",
    "        self.head10 = nn.Linear(128,2)\n",
    "        self.sig10 = nn.Sigmoid()\n",
    "        self.head11 = nn.Linear(128,2)\n",
    "        self.sig11 = nn.Sigmoid()\n",
    "        self.head12 = nn.Linear(128,2)\n",
    "        self.sig12 = nn.Sigmoid()\n",
    "        # self.head_dict = {}\n",
    "        # for i in range(12):\n",
    "        #     name = f\"head{i}\"\n",
    "        #     self.head_dict[name] = nn.Linear(128,2)   # # in_shape = (32,128) | out_shape = (32,2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define the computations of the convolution block\n",
    "        out = self.max_pool1(self.conv1(x))\n",
    "        # print(out.shape)\n",
    "        # print(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.max_pool2(self.conv2(out))\n",
    "        out = self.relu2(out)\n",
    "        out = self.max_pool3(self.conv3(out))\n",
    "        out = self.relu3(out)\n",
    "        out = self.max_pool4(self.conv4(out))\n",
    "        out = self.relu4(out)\n",
    "\n",
    "        # Now define the computations of the fully connected layers.\n",
    "        # print(out.shape)\n",
    "        out = out.view(128,-1)\n",
    "        # print(out.shape)\n",
    "        # assert out.shape == (32, 160000)\n",
    "        out = self.relu5(self.batchnorm1(self.fc1(out)))\n",
    "        out = self.relu6(self.batchnorm2(self.fc2(out)))\n",
    "        out = self.relu7(self.batchnorm3(self.fc3(out)))\n",
    "\n",
    "        # Now we will define the computations of the 12 heads and heads and put all the outputs into one tensor and return that tensor.\n",
    "        # The out tensor would of the shape (12,32,2).\n",
    "        self.out_head1 = self.sig1(self.head1(out))  # 'food'\n",
    "        self.out_head2 = self.sig2(self.head2(out)) # animal\n",
    "        self.out_head3 = self.sig3(self.head3(out)) # furniture\n",
    "        self.out_head4 = self.sig4(self.head4(out)) # electronic\n",
    "        self.out_head5 = self.sig5(self.head5(out)) # kitchen\n",
    "        self.out_head6 = self.sig6(self.head6(out)) # vehicle\n",
    "        self.out_head7 = self.sig7(self.head7(out)) # person\n",
    "        self.out_head8 = self.sig8(self.head8(out)) # outdoor\n",
    "        self.out_head9 = self.sig9(self.head9(out)) # accessory\n",
    "        self.out_head10 = self.sig10(self.head10(out)) # sports\n",
    "        self.out_head11 = self.sig11(self.head11(out)) # appliance\n",
    "        self.out_head12 = self.sig12(self.head12(out)) # indoor\n",
    "        out_list = [self.out_head1,self.out_head2,self.out_head3,self.out_head4,self.out_head5,self.out_head6,self.out_head7,self.out_head8,\n",
    "                    self.out_head9,self.out_head10,self.out_head11,self.out_head12]\n",
    "        # out_dict = {}\n",
    "        # for i,key in enumerate(self.head_dict.keys()):\n",
    "        #     name = f\"out_head{i}\"\n",
    "        #     layer = self.head_dict[key]\n",
    "        #     out_dict[name] = layer(out)\n",
    "        # print(out_dict)\n",
    "        # print(out_dict['out_head0'].shape)\n",
    "        # out_tensor = torch.stack(list(out_dict.values()), dim=1)\n",
    "        # print(f\"the final output after all the heads is {out_tensor.shape}\")\n",
    "\n",
    "        out_tensor = torch.stack(out_list, dim = 1)\n",
    "        # print(f\"the shape of the final output tensor is {out_tensor.shape}\")\n",
    "\n",
    "        return out_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_train_data, exp_train_label = [],[]\n",
    "\n",
    "for i in range(128):\n",
    "    img, labels,_ = train_coco[i]\n",
    "    exp_train_data.append(img)\n",
    "    exp_train_label.append(labels)\n",
    "# exp_train_data = torch.tensor(exp_train_data)\n",
    "# exp_train_label = torch.tensor(exp_train_label)\n",
    "# print(exp_train_data.shape)\n",
    "# print(exp_train_label.shape)\n",
    "# print(len(exp_train_data), len(exp_train_label))\n",
    "exp_train_data = torch.stack(exp_train_data)\n",
    "exp_train_label = torch.stack(exp_train_label)\n",
    "exp_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_train_label[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv = SeqConvnet()\n",
    "# o = conv(exp_train_data)\n",
    "# print(o[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv = SeqConvnet()\n",
    "# o = conv(exp_train_data)\n",
    "# print(o[0])\n",
    "# c = torch.nn.BCELoss()\n",
    "# c(o, exp_train_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have the made the model. Next we need to test our model with some dummy data so that we can see that we are getting the correct outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that the model outputs the desired shapes of the ouputs which is 12 tensors of shape (32,2) i.e one tensor for each head of the class.\n",
    "```\n",
    "    out_tensor = (batch_size)*(Number_of_classes)*(present/not_present)\n",
    "```\n",
    "This woud be compared to our labels via the binary_crossentopy metric and we would then calculate the loss of individual heads and then we would average the individual losses and find our the model loss. Then we will backpropagate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(model, val_dataloader, device, loss_fn):\n",
    "    print(\"Validation is progressing\")\n",
    "    val_loss_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_img, val_label, _ in tqdm(val_dataloader, nrows = 1, disable=True):\n",
    "            # transfer the images and labels to the GPU\n",
    "            val_img = val_img.to(device)\n",
    "            val_label = val_label.to(device)\n",
    "\n",
    "            # Now run it through the model and get the val_logits\n",
    "            val_logits = model(val_img)\n",
    "\n",
    "            val_loss = loss_fn(val_logits, val_label)\n",
    "            out_val_loss = val_loss.clone().to(torch.device('cpu'))\n",
    "            val_loss_list.append(out_val_loss.item())\n",
    "            # val_loss += out_val_loss.item()\n",
    "            # val_i +=1\n",
    "    return val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will begin to write the training loop that will ingest the data and output the result.\n",
    "def training_loop(epochs, conv_model,train_dataloader,device,optimizer= None, val_dataloader=None, loss_fn = None):\n",
    "    \n",
    "    for epoch in trange(epochs):\n",
    "        train_losses = []\n",
    "        # print(\"Training is Progressing\")\n",
    "        for img, label,_ in tqdm(train_dataloader, nrows=1):\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            # Now put the training data into the model to get the logits\n",
    "            pred = conv_model(img)\n",
    "\n",
    "            # Now we will zero out the optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # calculate the loss\n",
    "            loss = loss_fn(pred, label)\n",
    "\n",
    "            out_loss = loss.clone().to(device=torch.device('cpu'))\n",
    "\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "            # Next we will update the parameters\n",
    "            optimizer.step()\n",
    "            train_losses.append(out_loss.item())\n",
    "        \n",
    "        # val_loss_list = validation_loop(model = conv_model, val_dataloader=val_dataloader, device = device, loss_fn= loss_fn)\n",
    "        print(f\"Epoch: {epoch} | Train_loss: {torch.tensor(train_losses).mean()}\") # | Val_loss : {val_loss_list.mean()}\")\n",
    "            \n",
    "\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Min loss reached with SGD = 0.441 with lr = 0.1     # We used the tanh non-linearity without batchnorm\n",
    "2. Min loss reached with Adam = 0.47 with a lr = 0.1   # we used the tanh non-linearity without batchnorm\n",
    "3. Min loss reached with Adam = 0.442 with a lr = 0.1, weight_decay = 0.01   # we used the relu non-linearity without batchnorm\\\n",
    "previously we were not able to achieve good losses because we were not calculating the output tensor correctly, becuase it is a multilabel classification problem which predicts the whether a class is present or not present. The mistake that we were doing is that we were not calculating the probabilities of each head and just inputting the logits to the binary crossentopy loss. Instead what we should have done is that we should calculate the probabilities of prescence or absence of each class and then feed the output into the Binary crossentropy loss.\n",
    "4. Min loss that we achieved with Adam = 0.72 with a lr = 0.001  # we used relu without batchnorm(this was after we did the above fix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SeqConvnet                               --\n",
       "├─Conv2d: 1-1                            1,792\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─ReLU: 1-3                              --\n",
       "├─Conv2d: 1-4                            18,464\n",
       "├─MaxPool2d: 1-5                         --\n",
       "├─ReLU: 1-6                              --\n",
       "├─Conv2d: 1-7                            4,624\n",
       "├─MaxPool2d: 1-8                         --\n",
       "├─ReLU: 1-9                              --\n",
       "├─Conv2d: 1-10                           1,160\n",
       "├─MaxPool2d: 1-11                        --\n",
       "├─ReLU: 1-12                             --\n",
       "├─Linear: 1-13                           2,101,248\n",
       "├─BatchNorm1d: 1-14                      8,192\n",
       "├─ReLU: 1-15                             --\n",
       "├─Linear: 1-16                           4,195,328\n",
       "├─BatchNorm1d: 1-17                      2,048\n",
       "├─ReLU: 1-18                             --\n",
       "├─Linear: 1-19                           131,200\n",
       "├─BatchNorm1d: 1-20                      256\n",
       "├─ReLU: 1-21                             --\n",
       "├─Linear: 1-22                           258\n",
       "├─Sigmoid: 1-23                          --\n",
       "├─Linear: 1-24                           258\n",
       "├─Sigmoid: 1-25                          --\n",
       "├─Linear: 1-26                           258\n",
       "├─Sigmoid: 1-27                          --\n",
       "├─Linear: 1-28                           258\n",
       "├─Sigmoid: 1-29                          --\n",
       "├─Linear: 1-30                           258\n",
       "├─Sigmoid: 1-31                          --\n",
       "├─Linear: 1-32                           258\n",
       "├─Sigmoid: 1-33                          --\n",
       "├─Linear: 1-34                           258\n",
       "├─Sigmoid: 1-35                          --\n",
       "├─Linear: 1-36                           258\n",
       "├─Sigmoid: 1-37                          --\n",
       "├─Linear: 1-38                           258\n",
       "├─Sigmoid: 1-39                          --\n",
       "├─Linear: 1-40                           258\n",
       "├─Sigmoid: 1-41                          --\n",
       "├─Linear: 1-42                           258\n",
       "├─Sigmoid: 1-43                          --\n",
       "├─Linear: 1-44                           258\n",
       "├─Sigmoid: 1-45                          --\n",
       "=================================================================\n",
       "Total params: 6,467,408\n",
       "Trainable params: 6,467,408\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(seq_convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    }
   ],
   "source": [
    "# First we will instantiate the model\n",
    "seq_convnet = SeqConvnet()\n",
    "bce_loss = torch.nn.BCELoss()\n",
    "seq_convnet = seq_convnet.to(device=device)\n",
    "optimizer_adam = optim.Adam(seq_convnet.parameters(), lr = 0.001)\n",
    "schedular = optim.lr_scheduler.ExponentialLR(optimizer=optimizer_adam, gamma=0.9, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fb171604aa4b35ba9b59ed060d0327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9022a20b914d4ebf9411cfdaaa2387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train_loss: 0.6493959426879883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f77405bf64446aabd01c7383c82776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train_loss: 0.5123721361160278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a6565d84b643b5bf33af19f0d479cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train_loss: 0.4362003207206726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1021690970346b4aa2d38005abbb570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train_loss: 0.3866893947124481\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98821dd577214323a9255adfa8a972a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train_loss: 0.3440282940864563\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8a800d7a4d43f1b7c5500bc905ac27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train_loss: 0.31158673763275146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601db7588a0c465fad1ee40e77861b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train_loss: 0.2815251350402832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bfca531526431aa298394c7776c131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train_loss: 0.24504156410694122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a8af28f7664d74bd3ae91e3a4a592d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train_loss: 0.2105756551027298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0783e7d9404fcb9fa26fd74220845b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train_loss: 0.18622803688049316\n"
     ]
    }
   ],
   "source": [
    "training_loop(10,device = device, conv_model=seq_convnet, train_dataloader=test_coco_dataloader, optimizer=optimizer_adam, loss_fn=bce_loss)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that we trained above was trained with the intention of overfitting a small subset of data. Now we will check the metrics of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SeqConvnet                               --\n",
       "├─Conv2d: 1-1                            1,792\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─ReLU: 1-3                              --\n",
       "├─Conv2d: 1-4                            18,464\n",
       "├─MaxPool2d: 1-5                         --\n",
       "├─ReLU: 1-6                              --\n",
       "├─Conv2d: 1-7                            4,624\n",
       "├─MaxPool2d: 1-8                         --\n",
       "├─ReLU: 1-9                              --\n",
       "├─Conv2d: 1-10                           1,160\n",
       "├─MaxPool2d: 1-11                        --\n",
       "├─ReLU: 1-12                             --\n",
       "├─Linear: 1-13                           262,656\n",
       "├─BatchNorm1d: 1-14                      1,024\n",
       "├─ReLU: 1-15                             --\n",
       "├─Linear: 1-16                           131,328\n",
       "├─BatchNorm1d: 1-17                      512\n",
       "├─ReLU: 1-18                             --\n",
       "├─Linear: 1-19                           32,896\n",
       "├─BatchNorm1d: 1-20                      256\n",
       "├─ReLU: 1-21                             --\n",
       "├─Linear: 1-22                           258\n",
       "├─Sigmoid: 1-23                          --\n",
       "├─Linear: 1-24                           258\n",
       "├─Sigmoid: 1-25                          --\n",
       "├─Linear: 1-26                           258\n",
       "├─Sigmoid: 1-27                          --\n",
       "├─Linear: 1-28                           258\n",
       "├─Sigmoid: 1-29                          --\n",
       "├─Linear: 1-30                           258\n",
       "├─Sigmoid: 1-31                          --\n",
       "├─Linear: 1-32                           258\n",
       "├─Sigmoid: 1-33                          --\n",
       "├─Linear: 1-34                           258\n",
       "├─Sigmoid: 1-35                          --\n",
       "├─Linear: 1-36                           258\n",
       "├─Sigmoid: 1-37                          --\n",
       "├─Linear: 1-38                           258\n",
       "├─Sigmoid: 1-39                          --\n",
       "├─Linear: 1-40                           258\n",
       "├─Sigmoid: 1-41                          --\n",
       "├─Linear: 1-42                           258\n",
       "├─Sigmoid: 1-43                          --\n",
       "├─Linear: 1-44                           258\n",
       "├─Sigmoid: 1-45                          --\n",
       "=================================================================\n",
       "Total params: 457,808\n",
       "Trainable params: 457,808\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(seq_convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4105244576931,\n",
       " 0.40146052837371826,\n",
       " 0.32220539450645447,\n",
       " 0.41178712248802185,\n",
       " 0.4429898262023926,\n",
       " 0.44441360235214233,\n",
       " 0.37629207968711853,\n",
       " 0.40180474519729614,\n",
       " 0.420118510723114,\n",
       " 0.43926286697387695,\n",
       " 0.42059749364852905,\n",
       " 0.34016185998916626,\n",
       " 0.3703218400478363,\n",
       " 0.3791232705116272,\n",
       " 0.4567175805568695,\n",
       " 0.4625483751296997,\n",
       " 0.38726913928985596,\n",
       " 0.36139461398124695,\n",
       " 0.3509107828140259,\n",
       " 0.4264286458492279,\n",
       " 0.4681588411331177,\n",
       " 0.43750593066215515,\n",
       " 0.3688054084777832,\n",
       " 0.4028228223323822,\n",
       " 0.4283648133277893,\n",
       " 0.47029441595077515,\n",
       " 0.42021259665489197,\n",
       " 0.33833691477775574,\n",
       " 0.32548588514328003,\n",
       " 0.37759456038475037,\n",
       " 0.4459021985530853,\n",
       " 0.4668058753013611,\n",
       " 0.4027005136013031,\n",
       " 0.40450185537338257,\n",
       " 0.3765893876552582,\n",
       " 0.45167598128318787,\n",
       " 0.4379539489746094,\n",
       " 0.36664098501205444,\n",
       " 0.3533148467540741,\n",
       " 0.37280043959617615,\n",
       " 0.4211289882659912,\n",
       " 0.4412575364112854,\n",
       " 0.34760135412216187,\n",
       " 0.3974948823451996,\n",
       " 0.38323959708213806,\n",
       " 0.4345957040786743,\n",
       " 0.4470174312591553,\n",
       " 0.3601577877998352,\n",
       " 0.3777174949645996,\n",
       " 0.4092526137828827,\n",
       " 0.4323253631591797,\n",
       " 0.4603065848350525,\n",
       " 0.4066159725189209,\n",
       " 0.3489324450492859,\n",
       " 0.3833904266357422,\n",
       " 0.4567781388759613,\n",
       " 0.47240814566612244,\n",
       " 0.36096858978271484,\n",
       " 0.37796005606651306,\n",
       " 0.34154900908470154,\n",
       " 0.3703334331512451,\n",
       " 0.4555003046989441,\n",
       " 0.4301203191280365,\n",
       " 0.3591550588607788,\n",
       " 0.3384077548980713,\n",
       " 0.37713706493377686,\n",
       " 0.4390481114387512,\n",
       " 0.42487168312072754,\n",
       " 0.36308884620666504,\n",
       " 0.35976874828338623,\n",
       " 0.4012226462364197,\n",
       " 0.45269787311553955,\n",
       " 0.4467897117137909,\n",
       " 0.3794352412223816,\n",
       " 0.3919874131679535,\n",
       " 0.3912433087825775,\n",
       " 0.43762004375457764,\n",
       " 0.44129523634910583,\n",
       " 0.3658883571624756,\n",
       " 0.3553038537502289,\n",
       " 0.42722731828689575,\n",
       " 0.42311859130859375,\n",
       " 0.42275065183639526,\n",
       " 0.41817474365234375,\n",
       " 0.36234498023986816,\n",
       " 0.3708589971065521,\n",
       " 0.4078570306301117,\n",
       " 0.4106005132198334,\n",
       " 0.3509713113307953,\n",
       " 0.37637829780578613,\n",
       " 0.36431849002838135,\n",
       " 0.4424232840538025,\n",
       " 0.447518914937973,\n",
       " 0.3671027421951294,\n",
       " 0.3859595060348511,\n",
       " 0.42172715067863464,\n",
       " 0.38801223039627075,\n",
       " 0.4375578761100769,\n",
       " 0.3653147220611572,\n",
       " 0.3543296754360199,\n",
       " 0.3383183479309082,\n",
       " 0.41683149337768555,\n",
       " 0.4915740489959717,\n",
       " 0.3784930408000946,\n",
       " 0.4060816168785095,\n",
       " 0.3646578788757324,\n",
       " 0.3985227048397064,\n",
       " 0.44252973794937134,\n",
       " 0.45462438464164734,\n",
       " 0.349152535200119,\n",
       " 0.3564576506614685,\n",
       " 0.3658847212791443,\n",
       " 0.45536673069000244,\n",
       " 0.4165405035018921,\n",
       " 0.3869702219963074,\n",
       " 0.3532538115978241,\n",
       " 0.381600946187973,\n",
       " 0.4279775619506836,\n",
       " 0.4665522575378418,\n",
       " 0.38573694229125977,\n",
       " 0.37264856696128845,\n",
       " 0.4177882671356201,\n",
       " 0.4325094223022461,\n",
       " 0.4279935359954834,\n",
       " 0.3699881434440613,\n",
       " 0.35153335332870483,\n",
       " 0.3764323890209198,\n",
       " 0.4422701299190521,\n",
       " 0.4424319267272949,\n",
       " 0.36720794439315796,\n",
       " 0.40024352073669434,\n",
       " 0.2877731919288635,\n",
       " 0.3897150158882141,\n",
       " 0.4758685529232025,\n",
       " 0.3608676791191101,\n",
       " 0.3641713559627533,\n",
       " 0.3673963248729706,\n",
       " 0.4053207337856293,\n",
       " 0.4642117917537689,\n",
       " 0.38356733322143555,\n",
       " 0.39465293288230896,\n",
       " 0.37496399879455566,\n",
       " 0.4376642107963562,\n",
       " 0.45774728059768677,\n",
       " 0.4115368723869324,\n",
       " 0.35759755969047546,\n",
       " 0.38503897190093994,\n",
       " 0.41357630491256714,\n",
       " 0.450075626373291,\n",
       " 0.4529281258583069,\n",
       " 0.39658409357070923,\n",
       " 0.40345728397369385,\n",
       " 0.3819466531276703,\n",
       " 0.4506072402000427,\n",
       " 0.46009311079978943,\n",
       " 0.3422526717185974,\n",
       " 0.3426097333431244,\n",
       " 0.3474535346031189,\n",
       " 0.4214171767234802,\n",
       " 0.49075573682785034,\n",
       " 0.3950170874595642,\n",
       " 0.3668264150619507,\n",
       " 0.4048369824886322,\n",
       " 0.42966872453689575,\n",
       " 0.4448939263820648,\n",
       " 0.39696869254112244,\n",
       " 0.39714404940605164,\n",
       " 0.3666040301322937,\n",
       " 0.43625277280807495,\n",
       " 0.43661031126976013,\n",
       " 0.38931775093078613,\n",
       " 0.35911819338798523,\n",
       " 0.3980223834514618,\n",
       " 0.3966870903968811,\n",
       " 0.456622838973999,\n",
       " 0.38669079542160034,\n",
       " 0.4067079424858093,\n",
       " 0.36056995391845703,\n",
       " 0.4095233082771301,\n",
       " 0.4836026132106781,\n",
       " 0.4293299615383148,\n",
       " 0.41243046522140503,\n",
       " 0.3285432457923889,\n",
       " 0.40763187408447266,\n",
       " 0.45314690470695496,\n",
       " 0.4238598346710205,\n",
       " 0.3957012891769409,\n",
       " 0.3538993000984192,\n",
       " 0.39776885509490967,\n",
       " 0.4226548373699188,\n",
       " 0.4287338852882385,\n",
       " 0.39596056938171387,\n",
       " 0.36449354887008667,\n",
       " 0.39585262537002563,\n",
       " 0.40450888872146606,\n",
       " 0.4620313048362732,\n",
       " 0.35261839628219604,\n",
       " 0.3583766222000122,\n",
       " 0.36555981636047363,\n",
       " 0.5000516176223755,\n",
       " 0.47773027420043945,\n",
       " 0.39006781578063965,\n",
       " 0.40441185235977173,\n",
       " 0.39956313371658325,\n",
       " 0.40712055563926697,\n",
       " 0.4677979350090027,\n",
       " 0.4029461741447449,\n",
       " 0.34783875942230225,\n",
       " 0.37449002265930176,\n",
       " 0.4126269817352295,\n",
       " 0.4531908929347992,\n",
       " 0.4147588610649109,\n",
       " 0.3663121163845062,\n",
       " 0.34253156185150146,\n",
       " 0.3558275103569031,\n",
       " 0.40651604533195496,\n",
       " 0.43594956398010254,\n",
       " 0.36128100752830505,\n",
       " 0.36519449949264526,\n",
       " 0.377471387386322,\n",
       " 0.4279201626777649,\n",
       " 0.46503087878227234,\n",
       " 0.4108116030693054,\n",
       " 0.4035682678222656,\n",
       " 0.36554571986198425,\n",
       " 0.4126370847225189,\n",
       " 0.4472343325614929,\n",
       " 0.40444111824035645,\n",
       " 0.3905339241027832,\n",
       " 0.3684435486793518,\n",
       " 0.3906998038291931,\n",
       " 0.45293936133384705,\n",
       " 0.441556453704834,\n",
       " 0.4042266309261322,\n",
       " 0.3712562918663025,\n",
       " 0.3981294631958008,\n",
       " 0.4426858425140381,\n",
       " 0.443354070186615,\n",
       " 0.34396523237228394,\n",
       " 0.34726834297180176,\n",
       " 0.34999117255210876,\n",
       " 0.40611791610717773,\n",
       " 0.4708127975463867,\n",
       " 0.404549777507782,\n",
       " 0.40700221061706543,\n",
       " 0.3520180583000183,\n",
       " 0.44687700271606445,\n",
       " 0.45856761932373047,\n",
       " 0.431105375289917,\n",
       " 0.3970794677734375,\n",
       " 0.3438284993171692,\n",
       " 0.4122703969478607,\n",
       " 0.46048641204833984,\n",
       " 0.42254194617271423,\n",
       " 0.3518393933773041,\n",
       " 0.36582180857658386,\n",
       " 0.35681018233299255,\n",
       " 0.4355577826499939,\n",
       " 0.43522876501083374,\n",
       " 0.36664146184921265,\n",
       " 0.37607237696647644,\n",
       " 0.3853638768196106,\n",
       " 0.42788633704185486,\n",
       " 0.43901270627975464,\n",
       " 0.3604978322982788,\n",
       " 0.35971948504447937,\n",
       " 0.3468126058578491,\n",
       " 0.42388635873794556,\n",
       " 0.4579727351665497,\n",
       " 0.3702388405799866,\n",
       " 0.41301092505455017,\n",
       " 0.3477005958557129,\n",
       " 0.42208132147789,\n",
       " 0.47936734557151794,\n",
       " 0.38055509328842163,\n",
       " 0.34191378951072693,\n",
       " 0.3749046325683594,\n",
       " 0.4218805432319641,\n",
       " 0.4308443069458008,\n",
       " 0.4100569188594818,\n",
       " 0.369337797164917,\n",
       " 0.36181318759918213,\n",
       " 0.4118906855583191,\n",
       " 0.45245248079299927,\n",
       " 0.39014357328414917,\n",
       " 0.347339391708374,\n",
       " 0.35529470443725586,\n",
       " 0.41853010654449463,\n",
       " 0.4583003520965576,\n",
       " 0.37836605310440063,\n",
       " 0.37089627981185913,\n",
       " 0.3525319993495941,\n",
       " 0.4214801788330078,\n",
       " 0.46184787154197693,\n",
       " 0.44721168279647827,\n",
       " 0.34687718749046326,\n",
       " 0.31679365038871765,\n",
       " 0.39631304144859314,\n",
       " 0.4465186595916748,\n",
       " 0.4205746352672577,\n",
       " 0.3657647967338562,\n",
       " 0.39372897148132324,\n",
       " 0.4104878902435303,\n",
       " 0.4284140467643738,\n",
       " 0.4562385678291321,\n",
       " 0.360670268535614,\n",
       " 0.3851581811904907,\n",
       " 0.41045674681663513,\n",
       " 0.4512995183467865,\n",
       " 0.46241864562034607,\n",
       " 0.36571329832077026,\n",
       " 0.36733776330947876,\n",
       " 0.41557884216308594,\n",
       " 0.48410654067993164,\n",
       " 0.44139957427978516,\n",
       " 0.3989742696285248,\n",
       " 0.3792674243450165,\n",
       " 0.3744288384914398,\n",
       " 0.42792218923568726,\n",
       " 0.46077728271484375,\n",
       " 0.3556233048439026,\n",
       " 0.3532387912273407,\n",
       " 0.37287378311157227,\n",
       " 0.45448264479637146,\n",
       " 0.4860019087791443,\n",
       " 0.33716481924057007,\n",
       " 0.35172009468078613,\n",
       " 0.376654714345932,\n",
       " 0.4114183783531189,\n",
       " 0.45637068152427673,\n",
       " 0.3613263964653015,\n",
       " 0.3645762801170349,\n",
       " 0.3528427481651306,\n",
       " 0.4103658199310303,\n",
       " 0.43732643127441406,\n",
       " 0.4066029489040375,\n",
       " 0.4093663692474365,\n",
       " 0.38405176997184753,\n",
       " 0.3653956651687622,\n",
       " 0.4354405403137207,\n",
       " 0.4394996762275696,\n",
       " 0.37406468391418457,\n",
       " 0.332902729511261,\n",
       " 0.4486808776855469,\n",
       " 0.4362137019634247,\n",
       " 0.4094323515892029,\n",
       " 0.34083864092826843,\n",
       " 0.3317938446998596,\n",
       " 0.4049645662307739,\n",
       " 0.42031329870224,\n",
       " 0.47927170991897583,\n",
       " 0.3625802993774414,\n",
       " 0.35503196716308594,\n",
       " 0.36102840304374695,\n",
       " 0.453817218542099,\n",
       " 0.4471316337585449,\n",
       " 0.3524777889251709,\n",
       " 0.3951128125190735,\n",
       " 0.3797711133956909,\n",
       " 0.4579101502895355,\n",
       " 0.46420180797576904,\n",
       " 0.36645257472991943,\n",
       " 0.3940093219280243,\n",
       " 0.35458382964134216,\n",
       " 0.4299620985984802,\n",
       " 0.4786994457244873,\n",
       " 0.3498896360397339,\n",
       " 0.3934047222137451,\n",
       " 0.347966730594635,\n",
       " 0.41847461462020874,\n",
       " 0.4689229428768158,\n",
       " 0.37607938051223755,\n",
       " 0.3783833384513855,\n",
       " 0.40031272172927856,\n",
       " 0.3773900866508484,\n",
       " 0.47107839584350586,\n",
       " 0.35970205068588257,\n",
       " 0.38371261954307556,\n",
       " 0.3471677899360657,\n",
       " 0.3875095248222351,\n",
       " 0.4588741064071655,\n",
       " 0.42305788397789,\n",
       " 0.35619375109672546,\n",
       " 0.33198755979537964,\n",
       " 0.38108164072036743,\n",
       " 0.4547254741191864,\n",
       " 0.4340125024318695,\n",
       " 0.3597773015499115,\n",
       " 0.3430570960044861,\n",
       " 0.32292795181274414,\n",
       " 0.38186484575271606,\n",
       " 0.43424510955810547,\n",
       " 0.3579576015472412,\n",
       " 0.3662654161453247,\n",
       " 0.34474286437034607,\n",
       " 0.4067555069923401,\n",
       " 0.46293970942497253,\n",
       " 0.3766081929206848,\n",
       " 0.4125802516937256,\n",
       " 0.36423560976982117,\n",
       " 0.40831243991851807,\n",
       " 0.4894498288631439,\n",
       " 0.4070392847061157,\n",
       " 0.3500076234340668,\n",
       " 0.35939711332321167,\n",
       " 0.3644086718559265,\n",
       " 0.4377916753292084,\n",
       " 0.41363614797592163,\n",
       " 0.3762211501598358,\n",
       " 0.35779398679733276,\n",
       " 0.37777256965637207,\n",
       " 0.41774702072143555,\n",
       " 0.46783554553985596,\n",
       " 0.3263883590698242,\n",
       " 0.36595067381858826,\n",
       " 0.4118000864982605]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets save the model\n",
    "torch.save(seq_convnet.state_dict(), 'F://coco/saved_models/seq_convnet_batch_norm_full.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqConvnet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (max_pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu3): ReLU()\n",
       "  (conv4): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (max_pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4): ReLU()\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu5): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (batchnorm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu6): ReLU()\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (batchnorm3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu7): ReLU()\n",
       "  (head1): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig1): Sigmoid()\n",
       "  (head2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig2): Sigmoid()\n",
       "  (head3): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig3): Sigmoid()\n",
       "  (head4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig4): Sigmoid()\n",
       "  (head5): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig5): Sigmoid()\n",
       "  (head6): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig6): Sigmoid()\n",
       "  (head7): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig7): Sigmoid()\n",
       "  (head8): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig8): Sigmoid()\n",
       "  (head9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig9): Sigmoid()\n",
       "  (head10): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig10): Sigmoid()\n",
       "  (head11): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig11): Sigmoid()\n",
       "  (head12): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (sig12): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_convnet = SeqConvnet()\n",
    "seq_convnet.load_state_dict(torch.load('F://coco/saved_models/seq_convnet_batch_norm_full.pt'))\n",
    "seq_convnet.to(device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will se how the model performs on when classifying the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First we will get the logits and then what we will do is that we will get the probabilities associated with each class\n",
    "# with torch.no_grad():\n",
    "#     for data, labels, _ in tqdm(val_dataloader, nrows = 1, disable=True):\n",
    "#         data = data.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         val_logits = seq_convnet(data)\n",
    "#         loss = F.binary_cross_entropy_with_logits(val_logits, labels)\n",
    "#         # print(loss.item())\n",
    "#         break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a multilabel confusion matrix to see how our model performs. We have used a custom library for multi-label confusion matrix called as mlcm. This was specifically designed for multilabel classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_mat = torch.zeros(12,12)\n",
    "def make_confusion_mat(logits_tensor, labels_tensor):\n",
    "    logits_tensor_argmax = torch.argmax(logits_tensor, dim = 2)\n",
    "    labels_tensor_argmax = torch.argmax(labels_tensor, dim = 2)\n",
    "    batch_conf_mat = mlcm.cm(labels_tensor_argmax.numpy(), logits_tensor_argmax.numpy(), print_note=False)\n",
    "    \n",
    "    return batch_conf_mat\n",
    "\n",
    "# px.imshow(confusion_mat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add each batch confusion matrix to another matrix and then we would visualize the confusion matrix for the whole training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf_mat = torch.zeros((13,13))\n",
    "seq_convnet.eval()\n",
    "seq_convnet = seq_convnet.to(device=device)\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for data, label, _ in val_dataloader:\n",
    "        data = data.to(device = device)\n",
    "        \n",
    "        # label = label.to(device = device)\n",
    "        logits = seq_convnet(data)\n",
    "        label = label.to(device= torch.device('cpu'))\n",
    "        logits = logits.to(device= torch.device('cpu'))\n",
    "        batch_conf_mat = make_confusion_mat(logits_tensor= logits, labels_tensor=label)\n",
    "        conf_mat += batch_conf_mat[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3600e+02, 2.5000e+01, 7.0000e+01, 0.0000e+00, 2.0000e+00, 1.0000e+00,\n",
       "         4.2000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         5.6800e+02],\n",
       "        [5.0000e+00, 5.6000e+02, 2.2000e+01, 0.0000e+00, 1.0000e+00, 4.0000e+00,\n",
       "         7.6000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         6.5600e+02],\n",
       "        [1.9000e+01, 5.6000e+01, 2.9400e+02, 0.0000e+00, 2.0000e+00, 8.0000e+00,\n",
       "         1.0000e+02, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.1820e+03],\n",
       "        [6.0000e+00, 1.6000e+01, 3.5000e+01, 0.0000e+00, 2.0000e+00, 3.0000e+00,\n",
       "         5.7000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         6.2200e+02],\n",
       "        [1.7000e+01, 2.4000e+01, 6.0000e+01, 0.0000e+00, 1.1000e+01, 3.0000e+00,\n",
       "         8.8000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         9.8300e+02],\n",
       "        [1.0000e+01, 1.6700e+02, 1.7000e+01, 0.0000e+00, 0.0000e+00, 1.1000e+02,\n",
       "         1.6400e+02, 0.0000e+00, 0.0000e+00, 2.2000e+01, 0.0000e+00, 0.0000e+00,\n",
       "         1.1250e+03],\n",
       "        [2.2000e+01, 3.7300e+02, 6.8000e+01, 0.0000e+00, 4.0000e+00, 1.0000e+00,\n",
       "         1.4160e+03, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.8660e+03],\n",
       "        [7.0000e+00, 1.0100e+02, 1.7000e+01, 0.0000e+00, 1.0000e+00, 6.0000e+00,\n",
       "         7.5000e+01, 0.0000e+00, 0.0000e+00, 9.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         5.2300e+02],\n",
       "        [9.0000e+00, 6.1000e+01, 2.5000e+01, 0.0000e+00, 1.0000e+00, 1.5000e+01,\n",
       "         2.5000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         9.0800e+02],\n",
       "        [6.0000e+00, 2.5400e+02, 6.0000e+00, 0.0000e+00, 0.0000e+00, 2.1000e+01,\n",
       "         8.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "         9.5100e+02],\n",
       "        [2.0000e+00, 1.2000e+01, 3.8000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         2.8000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.4900e+02],\n",
       "        [2.0000e+01, 3.9000e+01, 4.7000e+01, 0.0000e+00, 5.0000e+00, 6.0000e+00,\n",
       "         1.1200e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         6.6100e+02],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           236,
           25,
           70,
           0,
           2,
           1,
           42,
           0,
           0,
           1,
           0,
           0,
           568
          ],
          [
           5,
           560,
           22,
           0,
           1,
           4,
           76,
           0,
           0,
           6,
           0,
           0,
           656
          ],
          [
           19,
           56,
           294,
           0,
           2,
           8,
           100,
           0,
           0,
           1,
           0,
           0,
           1182
          ],
          [
           6,
           16,
           35,
           0,
           2,
           3,
           57,
           0,
           0,
           2,
           0,
           0,
           622
          ],
          [
           17,
           24,
           60,
           0,
           11,
           3,
           88,
           0,
           0,
           2,
           0,
           0,
           983
          ],
          [
           10,
           167,
           17,
           0,
           0,
           110,
           164,
           0,
           0,
           22,
           0,
           0,
           1125
          ],
          [
           22,
           373,
           68,
           0,
           4,
           1,
           1416,
           0,
           0,
           1,
           0,
           0,
           1866
          ],
          [
           7,
           101,
           17,
           0,
           1,
           6,
           75,
           0,
           0,
           9,
           0,
           0,
           523
          ],
          [
           9,
           61,
           25,
           0,
           1,
           15,
           25,
           0,
           0,
           4,
           0,
           0,
           908
          ],
          [
           6,
           254,
           6,
           0,
           0,
           21,
           8,
           0,
           0,
           60,
           0,
           0,
           951
          ],
          [
           2,
           12,
           38,
           0,
           0,
           0,
           28,
           0,
           0,
           0,
           0,
           0,
           349
          ],
          [
           20,
           39,
           47,
           0,
           5,
           6,
           112,
           0,
           0,
           0,
           0,
           0,
           661
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(254, 245, 244)"
          ],
          [
           0.09090909090909091,
           "rgb(222, 224, 210)"
          ],
          [
           0.18181818181818182,
           "rgb(189, 206, 181)"
          ],
          [
           0.2727272727272727,
           "rgb(153, 189, 156)"
          ],
          [
           0.36363636363636365,
           "rgb(110, 173, 138)"
          ],
          [
           0.45454545454545453,
           "rgb(65, 157, 129)"
          ],
          [
           0.5454545454545454,
           "rgb(25, 137, 125)"
          ],
          [
           0.6363636363636364,
           "rgb(18, 116, 117)"
          ],
          [
           0.7272727272727273,
           "rgb(25, 94, 106)"
          ],
          [
           0.8181818181818182,
           "rgb(28, 72, 93)"
          ],
          [
           0.9090909090909091,
           "rgb(25, 51, 80)"
          ],
          [
           1,
           "rgb(20, 29, 67)"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "tickmode": "array",
         "ticktext": [
          "food",
          "animal",
          "furniture",
          "electronic",
          "kitchen",
          "vehicle",
          "person",
          "outdoor",
          "accessory",
          "sports",
          "appliance",
          "indoor"
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11
         ]
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "tickmode": "array",
         "ticktext": [
          "food",
          "animal",
          "furniture",
          "electronic",
          "kitchen",
          "vehicle",
          "person",
          "outdoor",
          "accessory",
          "sports",
          "appliance",
          "indoor"
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = px.imshow(conf_mat, color_continuous_scale='tempo')\n",
    "img.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = [0,1, 2, 3, 4, 5,6, 7,8, 9,10, 11],\n",
    "        ticktext =['food', 'animal', 'furniture', 'electronic', 'kitchen', 'vehicle',\n",
    "       'person', 'outdoor', 'accessory', 'sports', 'appliance', 'indoor']\n",
    "    ),\n",
    "    yaxis = dict\n",
    "    (\n",
    "        tickmode = 'array',\n",
    "        tickvals = [0,1, 2, 3, 4, 5,6, 7,8, 9,10, 11],\n",
    "        ticktext = ['food', 'animal', 'furniture', 'electronic', 'kitchen', 'vehicle',\n",
    "       'person', 'outdoor', 'accessory', 'sports', 'appliance', 'indoor']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['food', 'animal', 'furniture', 'electronic', 'kitchen', 'vehicle',\n",
       "       'person', 'outdoor', 'accessory', 'sports', 'appliance', 'indoor'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = image_label_df.columns[2:]\n",
    "class_names.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will implement the google net architecture.\n",
    "Alex Net architecture\n",
    "--- \n",
    "| Layer | Type | Maps | Size | Kernel size | Stride | Padding | Activation |\n",
    "| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |\n",
    "| Out | Fully connected | – | 1,000 | – | – | – | Softmax |\n",
    "| F10 | Fully connected | – | 4,096 | – | – | – | ReLU |\n",
    "| F9 | Fully connected| – | 4,096 | – | – | – ReLU |\n",
    "| S8 | Max pooling | 256 | 6 × 6 | 3 × 3 | 2 | valid | – |\n",
    "| C7 | Convolution | 256 | 13 × 13 | 3 × 3 | 1 | same | ReLU |\n",
    "| C6 | Convolution | 384 | 13 × 13 | 3 × 3 | 1 | same | ReLU |\n",
    "| C5 | Convolution | 384 | 13 × 13 | 3 × 3 | 1 | same | ReLU |\n",
    "| S4 | Max pooling | 256 | 13 × 13 | 3 × 3 | 2 | valid | – |\n",
    "| C3 | Convolution | 256 | 27 × 27 | 5 × 5 | 1 | same |ReLU |\n",
    "| S2 | Max pooling | 96 | 27 × 27 | 3 × 3 | 2 | valid | – |\n",
    "| C1 | Convolution | 96 | 55 × 55 | 11 × 11 | 4 |valid | ReLU |\n",
    "| In | Input | 3 (RGB) | 227 × 227 | – | – | – | – |\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # resizing the image to alex net required size\n",
    "        self.input_size = (227,227)\n",
    "        self.transform = Resize(self.input_size)\n",
    "        # first convolution layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=(11,11), stride=4, padding='valid') # out_shape = (96,55,55)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(3,3),stride = 2)  # out_shape = ()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256,stride = 1, kernel_size=(5,5), padding = 'same') # out_shape = ()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(3,3),stride =2) # out_shape = ()\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=(3,3), stride = 1, padding = 'same') # out_shape = ()\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=(3,3), stride = 1, padding='same') # out_shape = ()\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=(3,3), stride = 1, padding='same') # out_shape = ()\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=(3,3),stride =2) # out_shape = (256,6,6)\n",
    "        self.fc1 = nn.Linear(256*6*6,4096) # out_shape = (128,4096)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(4096, 4096) # out_shape = (128,4096)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(4096, 128) # out_shape = (128,128)\n",
    "        self.relu8 = nn.ReLU()\n",
    "\n",
    "        # computation for the multi-label heads\n",
    "        \n",
    "        self.head1 = nn.Linear(128,2)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.head2 = nn.Linear(128,2)\n",
    "        self.sig2 = nn.Sigmoid()\n",
    "        self.head3 = nn.Linear(128,2)\n",
    "        self.sig3 = nn.Sigmoid()\n",
    "        self.head4 = nn.Linear(128,2)\n",
    "        self.sig4 = nn.Sigmoid()\n",
    "        self.head5 = nn.Linear(128,2)\n",
    "        self.sig5 = nn.Sigmoid()\n",
    "        self.head6 = nn.Linear(128,2)\n",
    "        self.sig6 = nn.Sigmoid()\n",
    "        self.head7 = nn.Linear(128,2)\n",
    "        self.sig7 = nn.Sigmoid()\n",
    "        self.head8 = nn.Linear(128,2)\n",
    "        self.sig8 = nn.Sigmoid()\n",
    "        self.head9 = nn.Linear(128,2)\n",
    "        self.sig9 = nn.Sigmoid()\n",
    "        self.head10 = nn.Linear(128,2)\n",
    "        self.sig10 = nn.Sigmoid()\n",
    "        self.head11 = nn.Linear(128,2)\n",
    "        self.sig11 = nn.Sigmoid()\n",
    "        self.head12 = nn.Linear(128,2)\n",
    "        self.sig12 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.transform(x)\n",
    "        print(out.shape)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.maxpool3(out)\n",
    "        # print(out.shape)\n",
    "        out = out.view(128, -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu6(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu7(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu8(out)\n",
    "\n",
    "\n",
    "        # Now we will define the computations of the 12 heads and heads and put all the outputs into one tensor and return that tensor.\n",
    "        # The out tensor would of the shape (12,32,2).\n",
    "        self.out_head1 = self.sig1(self.head1(out))  # 'food'\n",
    "        self.out_head2 = self.sig2(self.head2(out)) # animal\n",
    "        self.out_head3 = self.sig3(self.head3(out)) # furniture\n",
    "        self.out_head4 = self.sig4(self.head4(out)) # electronic\n",
    "        self.out_head5 = self.sig5(self.head5(out)) # kitchen\n",
    "        self.out_head6 = self.sig6(self.head6(out)) # vehicle\n",
    "        self.out_head7 = self.sig7(self.head7(out)) # person\n",
    "        self.out_head8 = self.sig8(self.head8(out)) # outdoor\n",
    "        self.out_head9 = self.sig9(self.head9(out)) # accessory\n",
    "        self.out_head10 = self.sig10(self.head10(out)) # sports\n",
    "        self.out_head11 = self.sig11(self.head11(out)) # appliance\n",
    "        self.out_head12 = self.sig12(self.head12(out)) # indoor\n",
    "        out_list = [self.out_head1,self.out_head2,self.out_head3,self.out_head4,self.out_head5,self.out_head6,self.out_head7,self.out_head8,\n",
    "                    self.out_head9,self.out_head10,self.out_head11,self.out_head12]\n",
    "\n",
    "        out_tensor = torch.stack(out_list, dim = 1)\n",
    "\n",
    "        return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 128, 128])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_train_data, exp_train_label = [],[]\n",
    "\n",
    "for i in range(128):\n",
    "    img, labels,_ = train_coco[i]\n",
    "    exp_train_data.append(img)\n",
    "    exp_train_label.append(labels)\n",
    "# exp_train_data = torch.tensor(exp_train_data)\n",
    "# exp_train_label = torch.tensor(exp_train_label)\n",
    "# print(exp_train_data.shape)\n",
    "# print(exp_train_label.shape)\n",
    "# print(len(exp_train_data), len(exp_train_label))\n",
    "exp_train_data = torch.stack(exp_train_data)\n",
    "exp_train_label = torch.stack(exp_train_label)\n",
    "exp_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 227, 227])\n",
      "tensor([[0.5014, 0.4606],\n",
      "        [0.5052, 0.5172],\n",
      "        [0.5125, 0.5468],\n",
      "        [0.4614, 0.4723],\n",
      "        [0.4669, 0.4502],\n",
      "        [0.5514, 0.5005],\n",
      "        [0.5617, 0.5364],\n",
      "        [0.4698, 0.4598],\n",
      "        [0.5029, 0.5069],\n",
      "        [0.4811, 0.5110],\n",
      "        [0.4826, 0.5524],\n",
      "        [0.4917, 0.5614]], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7021, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = AlexNet()\n",
    "o = conv(exp_train_data)\n",
    "print(o[0])\n",
    "c = torch.nn.BCELoss()\n",
    "c(o, exp_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "AlexNet                                  --\n",
       "├─Resize: 1-1                            --\n",
       "├─Conv2d: 1-2                            34,944\n",
       "├─ReLU: 1-3                              --\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Conv2d: 1-5                            614,656\n",
       "├─ReLU: 1-6                              --\n",
       "├─MaxPool2d: 1-7                         --\n",
       "├─Conv2d: 1-8                            885,120\n",
       "├─ReLU: 1-9                              --\n",
       "├─Conv2d: 1-10                           1,327,488\n",
       "├─ReLU: 1-11                             --\n",
       "├─Conv2d: 1-12                           884,992\n",
       "├─ReLU: 1-13                             --\n",
       "├─MaxPool2d: 1-14                        --\n",
       "├─Linear: 1-15                           37,752,832\n",
       "├─ReLU: 1-16                             --\n",
       "├─Linear: 1-17                           16,781,312\n",
       "├─ReLU: 1-18                             --\n",
       "├─Linear: 1-19                           524,416\n",
       "├─ReLU: 1-20                             --\n",
       "├─Linear: 1-21                           258\n",
       "├─Sigmoid: 1-22                          --\n",
       "├─Linear: 1-23                           258\n",
       "├─Sigmoid: 1-24                          --\n",
       "├─Linear: 1-25                           258\n",
       "├─Sigmoid: 1-26                          --\n",
       "├─Linear: 1-27                           258\n",
       "├─Sigmoid: 1-28                          --\n",
       "├─Linear: 1-29                           258\n",
       "├─Sigmoid: 1-30                          --\n",
       "├─Linear: 1-31                           258\n",
       "├─Sigmoid: 1-32                          --\n",
       "├─Linear: 1-33                           258\n",
       "├─Sigmoid: 1-34                          --\n",
       "├─Linear: 1-35                           258\n",
       "├─Sigmoid: 1-36                          --\n",
       "├─Linear: 1-37                           258\n",
       "├─Sigmoid: 1-38                          --\n",
       "├─Linear: 1-39                           258\n",
       "├─Sigmoid: 1-40                          --\n",
       "├─Linear: 1-41                           258\n",
       "├─Sigmoid: 1-42                          --\n",
       "├─Linear: 1-43                           258\n",
       "├─Sigmoid: 1-44                          --\n",
       "=================================================================\n",
       "Total params: 58,808,856\n",
       "Trainable params: 58,808,856\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(conv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that our alex net is defined clearly. Now we just need to run out batches through the network and work out the training and the validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will begin to write the training loop that will ingest the data and output the result.\n",
    "def training_loop(epochs, conv_model,train_dataloader,device,optimizer= None, val_dataloader=None, loss_fn = None):\n",
    "    \n",
    "    for epoch in trange(epochs):\n",
    "        train_losses = []\n",
    "        # print(\"Training is Progressing\")\n",
    "        for img, label,_ in tqdm(train_dataloader, nrows=1):\n",
    "            batch_losses = []\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            # Now put the training data into the model to get the logits\n",
    "            pred = conv_model(img)\n",
    "\n",
    "            # Now we will zero out the optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # calculate the loss\n",
    "            loss = loss_fn(pred, label)\n",
    "\n",
    "            out_loss = loss.clone().to(device=torch.device('cpu'))\n",
    "\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "            # Next we will update the parameters\n",
    "            optimizer.step()\n",
    "            # print(out_loss.item())\n",
    "            train_losses.append(out_loss.item())\n",
    "        \n",
    "        # val_loss_list = validation_loop(model = conv_model, val_dataloader=val_dataloader, device = device, loss_fn= loss_fn)\n",
    "        print(f\"Epoch: {epoch} | Train_loss: {torch.tensor(train_losses).mean().item()}\")# | Val_loss : {val_loss_list.mean()}\")\n",
    "        # break\n",
    "            \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_coco = CocoDataset(image_label_df=image_label_df, val_stride=5)\n",
    "# val_coco = CocoDataset(image_label_df=image_label_df,is_val_set_bool=True)\n",
    "\n",
    "# train_dataloader = DataLoader(dataset=train_coco, batch_size=128, pin_memory=True, drop_last=True)\n",
    "# val_dataloader = DataLoader(dataset=val_coco, batch_size=128,pin_memory=True, drop_last = True)\n",
    "\n",
    "test_coco = CocoDataset(image_label_df=image_label_df, test_data_set=True, test_stride=50)\n",
    "\n",
    "test_coco_dataloader = DataLoader(dataset=test_coco, batch_size=128, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n"
     ]
    }
   ],
   "source": [
    "print(len(test_coco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No we will define the model\n",
    "alex_conv = AlexNet()\n",
    "bce_loss = torch.nn.BCELoss()\n",
    "alex_conv = alex_conv.to(device=device)\n",
    "optimizer_adam = optim.Adam(alex_conv.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbce3b795074e61a07e751c1fd2be9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1423e337519b41e48dec11272c9c0bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train_loss: 23.11849021911621\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d567c7ab32ef4bd091c20cfac10a1cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train_loss: 20.970050811767578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cea72a58344648b304a6d81840fbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train_loss: 20.970050811767578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d69dd7447404da4be5349ea9963ee06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train_loss: 20.970050811767578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcba4bfe5d50409ca56ca98ae2f0c7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train_loss: 20.970050811767578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b031b0a9b23a4219b9af47d8cc44b7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train_loss: 20.970050811767578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7b87e9939e47d68ef3c9392dc966ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train_loss: 20.970050811767578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f7840a63b4413fb7e65aeec3305e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train_loss: 20.970050811767578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f9f88d57cc4b96868439d7d4f2b273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train_loss: 20.970050811767578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa12785872c7405fb1cbcdd686c0718e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train_loss: 20.970050811767578\n"
     ]
    }
   ],
   "source": [
    "training_loop(epochs = 10, conv_model=alex_conv, train_dataloader=test_coco_dataloader,\n",
    "                 val_dataloader=val_dataloader,optimizer=optimizer_adam, loss_fn=bce_loss, device = device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So there are two types of resenets. \n",
    "1. The vanilla resnets uses a resblock of 2 3x3 convolutions and skip connections.\n",
    "2. The second known as the bottleneck resblock uses 1x1 convolution then a 3x3 conv then a 1x1 conv:\n",
    "    1. The first 1x1 conv layer reduces the number of filters of the input from 256 to 64.\n",
    "    2. The second layer uses a 3x3 conv layer with 64 filters to learn the residual mapping.\n",
    "    3. The third layer uses a 1x1 conv layer with 256 filters to again increase the number of channels to 256 of the output.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets create a ResNet and see if it helps with our multilabel classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we would implement the resblock which has two 3x3 convolution and see how much we can get out of that training on the coco image dataset.\n",
    "class ResBlock64(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same')\n",
    "        self.b1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding = 'same')\n",
    "        self.b2 =nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Now lets define the computation of the resblock\n",
    "        out = self.relu1(self.b1(self.conv1(x)))\n",
    "        out = self.b2(self.conv2(out))\n",
    "        out_final = self.relu2(out + x)\n",
    "        \n",
    "        return out_final\n",
    "\n",
    "class ResBlock128(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding='same')\n",
    "        self.b1 = nn.BatchNorm2d(128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding = 'same')\n",
    "        self.b2 =nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Now lets define the computation of the resblock\n",
    "        out = self.relu1(self.b1(self.conv1(x)))\n",
    "        out = self.b2(self.conv2(out))\n",
    "        out_final = self.relu2(out + x)\n",
    "        return out_final\n",
    "\n",
    "class ResBlock256(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding='same')\n",
    "        self.b1 = nn.BatchNorm2d(256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding = 'same')\n",
    "        self.b2 =nn.BatchNorm2d(256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Now lets define the computation of the resblock\n",
    "        out = self.relu1(self.b1(self.conv1(x)))\n",
    "        out = self.b2(self.conv2(out))\n",
    "        out_final = self.relu2(out + x)\n",
    "        return out_final\n",
    "\n",
    "class ResBlock512(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same')\n",
    "        self.b1 = nn.BatchNorm2d(512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding = 'same')\n",
    "        self.b2 =nn.BatchNorm2d(512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Now lets define the computation of the resblock\n",
    "        out = self.relu1(self.b1(self.conv1(x)))\n",
    "        out = self.b2(self.conv2(out))\n",
    "        out_final = self.relu2(out + x)\n",
    "        return out_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have defined the resblocks. Now we need to define the full resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # The first layer will input an  image of 224x224\n",
    "        self.input_conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(7,7), padding = 'same') # in = (3,224,224) | out = (64,224,224)\n",
    "        self.max_pool1 = nn.MaxPool2d(2)  # in = (64,224,224) | out = (64,128,128)\n",
    "\n",
    "        self.resblocks64 = nn.Sequential(\n",
    "            *(3*[ResBlock64()]))                      # in = (64,128,128) | out = (64,128,128)\n",
    "        self.max_pool2 = nn.MaxPool2d(2)            # in = (64,128,128) | out = (64,64,64)\n",
    "        self.channel_inc1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same') # in = (64,64,64) | out = (128,64,64)\n",
    "\n",
    "        self.resblocks128 = nn.Sequential(\n",
    "            *(4*[ResBlock128()]))                     # in = (128,64,64) | out = (128,64,64)\n",
    "        self.max_pool3 = nn.MaxPool2d(2)            # in = (128,64,64) | out = (128,32,32)\n",
    "        self.channel_inc2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), padding='same')   # in = (128,32,32) | out = (256,32,32)\n",
    "\n",
    "        self.resblocks256 = nn.Sequential(      \n",
    "            *(6*[ResBlock256()]))                    # in = (256,32,32) | out = (256,32,32)\n",
    "        self.max_pool4 = nn.MaxPool2d(2)            # in = (256,16,16) | out = (256,16,16)\n",
    "        self.channel_inc3 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), padding='same')   # in = (512,16,16) | out = (512,16,16)\n",
    "\n",
    "        self.resblocks512 = nn.Sequential(\n",
    "            *(3*[ResBlock512()]))                     # in = (512,16,16) | out = (512,16,16)\n",
    "        self.max_pool5 = nn.MaxPool2d(2)            # in = (512,8,8) | out = (512,8,8)\n",
    "\n",
    "        # input to this layer would be (512,8,8)\n",
    "        self.fc1 = nn.Linear(512*8*8, 256)\n",
    "        self.bfc1 = nn.BatchNorm2d(256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bfc2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # self.fc3 = nn.Linear(512, 128)\n",
    "        # self.bfc3 = nn.BatchNorm2d(128)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Now we will need to define our output layers\n",
    "        # computation for the multi-label heads\n",
    "        \n",
    "        self.head1 = nn.Linear(128,2)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.head2 = nn.Linear(128,2)\n",
    "        self.sig2 = nn.Sigmoid()\n",
    "        self.head3 = nn.Linear(128,2)\n",
    "        self.sig3 = nn.Sigmoid()\n",
    "        self.head4 = nn.Linear(128,2)\n",
    "        self.sig4 = nn.Sigmoid()\n",
    "        self.head5 = nn.Linear(128,2)\n",
    "        self.sig5 = nn.Sigmoid()\n",
    "        self.head6 = nn.Linear(128,2)\n",
    "        self.sig6 = nn.Sigmoid()\n",
    "        self.head7 = nn.Linear(128,2)\n",
    "        self.sig7 = nn.Sigmoid()\n",
    "        self.head8 = nn.Linear(128,2)\n",
    "        self.sig8 = nn.Sigmoid()\n",
    "        self.head9 = nn.Linear(128,2)\n",
    "        self.sig9 = nn.Sigmoid()\n",
    "        self.head10 = nn.Linear(128,2)\n",
    "        self.sig10 = nn.Sigmoid()\n",
    "        self.head11 = nn.Linear(128,2)\n",
    "        self.sig11 = nn.Sigmoid()\n",
    "        self.head12 = nn.Linear(128,2)\n",
    "        self.sig12 = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\" This function would define the computations of the layers to produce the output\"\"\"\n",
    "        assert X.shape == (32,3,224,224)\n",
    "        print(self.input_conv(X).shape)\n",
    "        # output of the first layer conv and maxpool\n",
    "        out = self.max_pool1(self.input_conv(X))\n",
    "\n",
    "        # output of the first resblock, maxpool2, channel_inc1\n",
    "        out = self.channel_inc1(self.max_pool2(self.resblocks64(out)))\n",
    "\n",
    "        # output of  resblock128\n",
    "        out = self.channel_inc2(self.max_pool3(self.resblocks128(out)))\n",
    "\n",
    "        # output after resblock256\n",
    "        out = self.channel_inc3(self.max_pool4(self.resblocks256(out)))\n",
    "\n",
    "        # output after resblock 512\n",
    "        out = self.max_pool5(self.resblocks512(out))\n",
    "\n",
    "        # Now we will reshape the tensor to have a\n",
    "        out = out.view(128,-1)\n",
    "\n",
    "        # output of the first fully conected layer\n",
    "        out = self.relu1(self.bfc1(self.fc1(out)))\n",
    "\n",
    "        # output after second fully connected layer\n",
    "        out = self.relu2(self.bfc2(self.fc2(out)))\n",
    "\n",
    "        # output after the third fully connected layer\n",
    "        # out = self.relu3(self.bfc3(self.fc3(out)))\n",
    "\n",
    "\n",
    "        # Now we will define the computations of the 12 heads and heads and put all the outputs into one tensor and return that tensor.\n",
    "        self.out_head1 = self.sig1(self.head1(out))  # 'food'\n",
    "        self.out_head2 = self.sig2(self.head2(out)) # animal\n",
    "        self.out_head3 = self.sig3(self.head3(out)) # furniture\n",
    "        self.out_head4 = self.sig4(self.head4(out)) # electronic\n",
    "        self.out_head5 = self.sig5(self.head5(out)) # kitchen\n",
    "        self.out_head6 = self.sig6(self.head6(out)) # vehicle\n",
    "        self.out_head7 = self.sig7(self.head7(out)) # person\n",
    "        self.out_head8 = self.sig8(self.head8(out)) # outdoor\n",
    "        self.out_head9 = self.sig9(self.head9(out)) # accessory\n",
    "        self.out_head10 = self.sig10(self.head10(out)) # sports\n",
    "        self.out_head11 = self.sig11(self.head11(out)) # appliance\n",
    "        self.out_head12 = self.sig12(self.head12(out)) # indoor\n",
    "        out_list = [self.out_head1,self.out_head2,self.out_head3,self.out_head4,self.out_head5,self.out_head6,self.out_head7,self.out_head8,\n",
    "                    self.out_head9,self.out_head10,self.out_head11,self.out_head12]\n",
    "\n",
    "        out_tensor = torch.stack(out_list, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 2.87 GiB already allocated; 0 bytes free; 2.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m res_conv \u001b[39m=\u001b[39m ResNet()\n\u001b[1;32m----> 2\u001b[0m res_conv \u001b[39m=\u001b[39m res_conv\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m      3\u001b[0m summary(res_conv)\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 2.87 GiB already allocated; 0 bytes free; 2.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "res_conv = ResNet()\n",
    "res_conv = res_conv.to(device=device)\n",
    "summary(res_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 224, 224])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets get a batch of data and try to our model into our data.\n",
    "exp_train_data, exp_train_label = [],[]\n",
    "\n",
    "for i in range(32):\n",
    "    img, labels,_ = train_coco[i]\n",
    "    exp_train_data.append(img)\n",
    "    exp_train_label.append(labels)\n",
    "# exp_train_data = torch.tensor(exp_train_data)\n",
    "# exp_train_label = torch.tensor(exp_train_label)\n",
    "# print(exp_train_data.shape)\n",
    "# print(exp_train_label.shape)\n",
    "# print(len(exp_train_data), len(exp_train_label))\n",
    "exp_train_data = torch.stack(exp_train_data)\n",
    "exp_train_label = torch.stack(exp_train_label)\n",
    "exp_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_train_data = exp_train_data.to(device=device)\n",
    "exp_train_label = exp_train_label.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 224, 224])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 4.00 GiB total capacity; 2.79 GiB already allocated; 0 bytes free; 2.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res_conv(exp_train_data)\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[14], line 81\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     78\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchannel_inc1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_pool2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresblocks64(out)))\n\u001b[0;32m     80\u001b[0m \u001b[39m# output of  resblock128\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchannel_inc2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_pool3(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresblocks128(out)))\n\u001b[0;32m     83\u001b[0m \u001b[39m# output after resblock256\u001b[39;00m\n\u001b[0;32m     84\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchannel_inc3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_pool4(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresblocks256(out)))\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m, in \u001b[0;36mResBlock128.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)))\n\u001b[0;32m     33\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out))\n\u001b[1;32m---> 34\u001b[0m out_final \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu2(out \u001b[39m+\u001b[39;49m x)\n\u001b[0;32m     35\u001b[0m \u001b[39mreturn\u001b[39;00m out_final\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 4.00 GiB total capacity; 2.79 GiB already allocated; 0 bytes free; 2.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "res_conv(exp_train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model that we defined is too large to fit into memory. So we will define a the model with two 1x1 convolutions and one 3x3 convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we would implement the resblock which has two 3x3 convolution and see how much we can get out of that training on the coco image dataset.\n",
    "class ResBlock64(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = 1, padding = 'same')\n",
    "        self.b1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding='same')\n",
    "        self.b2 = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=1, padding = 'same')\n",
    "        self.b3 =nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Now lets define the computation of the resblock\n",
    "        out = self.relu1(self.b1(self.conv1(x)))\n",
    "        out = self.relu2(self.b2(self.conv2(out)))\n",
    "        out = self.b3(self.conv3(out))\n",
    "        out_final = self.relu3(out + x)\n",
    "        \n",
    "        return out_final\n",
    "\n",
    "class ResBlock128(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # First 1x1 conv layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=128, out_channels=32, kernel_size=1, padding='same')\n",
    "        self.b1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Second 3x3 conv layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding = 'same')\n",
    "        self.b2 =nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Third 1x1 conv layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=128, kernel_size=1, padding = 'same')\n",
    "        self.b3 =nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Now lets define the computation of the resblock\n",
    "        out = self.relu1(self.b1(self.conv1(x)))\n",
    "        out = self.relu2(self.b2(self.conv2(out)))\n",
    "        out = self.b3(self.conv3(out))\n",
    "        out_final = self.relu3(out + x)\n",
    "        return out_final\n",
    "\n",
    "class downsampleBlock(nn.Module):\n",
    "    \"\"\" This class defines a downsampling block which is used to half the image size and double the channels of an image.\"\"\"\n",
    "    def __init__(self, in_chan, out_chan):\n",
    "        super().__init__()\n",
    "        # Define the first 1x1 conv layer. This layer would increase the channels of the input\n",
    "        self.conv1 = nn.Conv2d(in_channels = in_chan, out_channels=out_chan, kernel_size=1, stride = 2)\n",
    "        self.b1 = nn.BatchNorm2d(out_chan)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Then define the 3x3 conv layer. This layer would decrease the size of the image while making the channels constant.\n",
    "        self.conv2 = nn.Conv2d(in_channels = out_chan, out_channels=out_chan, kernel_size=3, padding='same')\n",
    "        self.b2 = nn.BatchNorm2d(out_chan)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Now define the third 1x1 layer. This layer would increase the channels of the input so that it \n",
    "        self.conv3 = nn.Conv2d(in_channels = in_chan, out_channels=out_chan, kernel_size = 1, stride = 2)\n",
    "        self.b3 = nn.BatchNorm2d(out_chan)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.relu1(self.b1(self.conv1(X)))\n",
    "        out = self.b2(self.conv2(out))\n",
    "\n",
    "        out_short = self.b3(self.conv3(X))\n",
    "\n",
    "        out_final = self.relu2(out + out_short)\n",
    "\n",
    "        return out_final\n",
    "\n",
    "class ResBlock256(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # First 1x1 conv layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=256, out_channels=64, kernel_size=1, padding='same')\n",
    "        self.b1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Second 3x3 conv layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding = 'same')\n",
    "        self.b2 =nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Third 1x1 conv layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=1, padding = 'same')\n",
    "        self.b3 =nn.BatchNorm2d(256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Now lets define the computation of the resblock\n",
    "        out = self.relu1(self.b1(self.conv1(x)))\n",
    "        out = self.relu2(self.b2(self.conv2(out)))\n",
    "        out = self.b3(self.conv3(out))\n",
    "        out_final = self.relu3(out + x)\n",
    "        return out_final\n",
    "\n",
    "class ResBlock512(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # First 1x1 conv layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=512, out_channels=128, kernel_size=1, padding='same')\n",
    "        self.b1 = nn.BatchNorm2d(128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Second 3x3 conv layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding = 'same')\n",
    "        self.b2 =nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Third 1x1 conv layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=512, kernel_size=1, padding = 'same')\n",
    "        self.b3 =nn.BatchNorm2d(512)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Now lets define the computation of the resblock\n",
    "        out = self.relu1(self.b1(self.conv1(x)))\n",
    "        out = self.relu2(self.b2(self.conv2(out)))\n",
    "        out = self.b3(self.conv3(out))\n",
    "        out_final = self.relu3(out + x)\n",
    "        return out_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "p = torch.manual_seed(42)\n",
    "x = torch.randn(32,64,28,28)\n",
    "r_b64 = downsampleBlock(64,128)\n",
    "\n",
    "y = r_b64(x)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets make the full architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,batch_size = None):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        # The first layer will input an  image of 224x224\n",
    "        self.input_conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(7,7), padding = 'same') # in = (3,224,224) | out = (64,224,224)\n",
    "        self.max_pool1 = nn.MaxPool2d(2)  # in = (64,224,224) | out = (64,112,112)\n",
    "\n",
    "        self.resblocks64 = nn.Sequential(\n",
    "            *(3*[ResBlock64()]+[downsampleBlock(64,128)]))                      # in = (64,128,128) | out = (64,128,128)\n",
    "        # self.max_pool2 = nn.MaxPool2d(2)            # in = (64,128,128) | out = (64,64,64)\n",
    "        # self.channel_inc1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same') # in = (64,64,64) | out = (128,64,64)\n",
    "\n",
    "        self.resblocks128 = nn.Sequential(\n",
    "            *(3*[ResBlock128()]+[downsampleBlock(128,256)]))                     # in = (128,64,64) | out = (128,64,64)\n",
    "        # self.max_pool3 = nn.MaxPool2d(2)            # in = (128,64,64) | out = (128,32,32)\n",
    "        # self.channel_inc2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), padding='same')   # in = (128,32,32) | out = (256,32,32)\n",
    "\n",
    "        self.resblocks256 = nn.Sequential(      \n",
    "            *(5*[ResBlock256()]+[downsampleBlock(256,512)]))                    # in = (256,32,32) | out = (256,32,32)\n",
    "        # self.max_pool4 = nn.MaxPool2d(2)            # in = (256,16,16) | out = (256,16,16)\n",
    "        # self.channel_inc3 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), padding='same')   # in = (512,16,16) | out = (512,16,16)\n",
    "\n",
    "        self.resblocks512 = nn.Sequential(\n",
    "            *(2*[ResBlock512()]))                     # in = (512,16,16) | out = (512,16,16)\n",
    "        # self.max_pool5 = nn.MaxPool2d(2)            # in = (512,8,8) | out = (512,8,8)\n",
    "\n",
    "        # Now we would use a Global Average Pooling Layer which is just a mean on the first two image dimensions excluding the channel dim.\n",
    "        # But that would just be an operation in the forward pass\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.bfc2 = nn.BatchNorm1d(128)\n",
    "        self.relu_fc2 = nn.ReLU()\n",
    "\n",
    "        # self.fc3 = nn.Linear(512, 128)\n",
    "        # self.bfc3 = nn.BatchNorm2d(128)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Now we will need to define our output layers\n",
    "        # computation for the multi-label heads\n",
    "        \n",
    "        self.head1 = nn.Linear(128,2)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.head2 = nn.Linear(128,2)\n",
    "        self.sig2 = nn.Sigmoid()\n",
    "        self.head3 = nn.Linear(128,2)\n",
    "        self.sig3 = nn.Sigmoid()\n",
    "        self.head4 = nn.Linear(128,2)\n",
    "        self.sig4 = nn.Sigmoid()\n",
    "        self.head5 = nn.Linear(128,2)\n",
    "        self.sig5 = nn.Sigmoid()\n",
    "        self.head6 = nn.Linear(128,2)\n",
    "        self.sig6 = nn.Sigmoid()\n",
    "        self.head7 = nn.Linear(128,2)\n",
    "        self.sig7 = nn.Sigmoid()\n",
    "        self.head8 = nn.Linear(128,2)\n",
    "        self.sig8 = nn.Sigmoid()\n",
    "        self.head9 = nn.Linear(128,2)\n",
    "        self.sig9 = nn.Sigmoid()\n",
    "        self.head10 = nn.Linear(128,2)\n",
    "        self.sig10 = nn.Sigmoid()\n",
    "        self.head11 = nn.Linear(128,2)\n",
    "        self.sig11 = nn.Sigmoid()\n",
    "        self.head12 = nn.Linear(128,2)\n",
    "        self.sig12 = nn.Sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\" This function would define the computations of the layers to produce the output\"\"\"\n",
    "        # assert X.shape == (2,3,224,224)\n",
    "        print(self.input_conv(X).shape)\n",
    "        # output of the first layer conv and maxpool\n",
    "        out = self.max_pool1(self.input_conv(X))\n",
    "\n",
    "        # output of the first resblock, maxpool2, channel_inc1\n",
    "        out = self.resblocks64(out)\n",
    "\n",
    "        # output of  resblock128\n",
    "        out = self.resblocks128(out)\n",
    "\n",
    "        # output after resblock256\n",
    "        out = self.resblocks256(out)\n",
    "\n",
    "        # output after resblock 512\n",
    "        out =  self.resblocks512(out)\n",
    "\n",
    "        # Then we would use a global average pooling layer i.e mean on the image_height and width using torch.mean()\n",
    "        out = torch.mean(out, dim = (2,3), keepdim=True)\n",
    "        # Now we will reshape the tensor to have a\n",
    "        # out = out.view(128,-1)\n",
    "\n",
    "        out = out.view(self.batch_size,-1)\n",
    "        # output of the first fully conected layer\n",
    "        # out = self.relu1(self.bfc1(self.fc1(out)))\n",
    "        print(f\"The output after the average pooling op is {out.shape}\")\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.bfc2(out)\n",
    "        out = self.relu_fc2(out)\n",
    "        # output after second fully connected layer\n",
    "        # out = self.relu_fc2(self.bfc2(self.fc2(out)))\n",
    "\n",
    "        # output after the third fully connected layer\n",
    "        # out = self.relu3(self.bfc3(self.fc3(out)))\n",
    "\n",
    "\n",
    "        # Now we will define the computations of the 12 heads and heads and put all the outputs into one tensor and return that tensor.\n",
    "        self.out_head1 = self.sig1(self.head1(out))  # 'food'\n",
    "        self.out_head2 = self.sig2(self.head2(out)) # animal\n",
    "        self.out_head3 = self.sig3(self.head3(out)) # furniture\n",
    "        self.out_head4 = self.sig4(self.head4(out)) # electronic\n",
    "        self.out_head5 = self.sig5(self.head5(out)) # kitchen\n",
    "        self.out_head6 = self.sig6(self.head6(out)) # vehicle\n",
    "        self.out_head7 = self.sig7(self.head7(out)) # person\n",
    "        self.out_head8 = self.sig8(self.head8(out)) # outdoor\n",
    "        self.out_head9 = self.sig9(self.head9(out)) # accessory\n",
    "        self.out_head10 = self.sig10(self.head10(out)) # sports\n",
    "        self.out_head11 = self.sig11(self.head11(out)) # appliance\n",
    "        self.out_head12 = self.sig12(self.head12(out)) # indoor\n",
    "        out_list = [self.out_head1,self.out_head2,self.out_head3,self.out_head4,self.out_head5,self.out_head6,self.out_head7,self.out_head8,\n",
    "                    self.out_head9,self.out_head10,self.out_head11,self.out_head12]\n",
    "\n",
    "        out_tensor = torch.stack(out_list, dim = 1)\n",
    "        print(out_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 224, 224])\n",
      "The output after the average pooling op is torch.Size([32, 512])\n",
      "torch.Size([32, 12, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   --                        --\n",
       "├─Conv2d: 1-1                            [32, 64, 224, 224]        9,472\n",
       "├─Conv2d: 1-2                            [32, 64, 224, 224]        (recursive)\n",
       "├─MaxPool2d: 1-3                         [32, 64, 112, 112]        --\n",
       "├─Sequential: 1-4                        [32, 128, 56, 56]         --\n",
       "│    └─ResBlock64: 2-1                   [32, 64, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-1                  [32, 32, 112, 112]        2,080\n",
       "│    │    └─BatchNorm2d: 3-2             [32, 32, 112, 112]        64\n",
       "│    │    └─ReLU: 3-3                    [32, 32, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-4                  [32, 32, 112, 112]        9,248\n",
       "│    │    └─BatchNorm2d: 3-5             [32, 32, 112, 112]        64\n",
       "│    │    └─ReLU: 3-6                    [32, 32, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-7                  [32, 64, 112, 112]        2,112\n",
       "│    │    └─BatchNorm2d: 3-8             [32, 64, 112, 112]        128\n",
       "│    │    └─ReLU: 3-9                    [32, 64, 112, 112]        --\n",
       "│    └─ResBlock64: 2-2                   [32, 64, 112, 112]        (recursive)\n",
       "│    │    └─Conv2d: 3-10                 [32, 32, 112, 112]        (recursive)\n",
       "│    │    └─BatchNorm2d: 3-11            [32, 32, 112, 112]        (recursive)\n",
       "│    │    └─ReLU: 3-12                   [32, 32, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-13                 [32, 32, 112, 112]        (recursive)\n",
       "│    │    └─BatchNorm2d: 3-14            [32, 32, 112, 112]        (recursive)\n",
       "│    │    └─ReLU: 3-15                   [32, 32, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-16                 [32, 64, 112, 112]        (recursive)\n",
       "│    │    └─BatchNorm2d: 3-17            [32, 64, 112, 112]        (recursive)\n",
       "│    │    └─ReLU: 3-18                   [32, 64, 112, 112]        --\n",
       "│    └─ResBlock64: 2-3                   [32, 64, 112, 112]        (recursive)\n",
       "│    │    └─Conv2d: 3-19                 [32, 32, 112, 112]        (recursive)\n",
       "│    │    └─BatchNorm2d: 3-20            [32, 32, 112, 112]        (recursive)\n",
       "│    │    └─ReLU: 3-21                   [32, 32, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-22                 [32, 32, 112, 112]        (recursive)\n",
       "│    │    └─BatchNorm2d: 3-23            [32, 32, 112, 112]        (recursive)\n",
       "│    │    └─ReLU: 3-24                   [32, 32, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-25                 [32, 64, 112, 112]        (recursive)\n",
       "│    │    └─BatchNorm2d: 3-26            [32, 64, 112, 112]        (recursive)\n",
       "│    │    └─ReLU: 3-27                   [32, 64, 112, 112]        --\n",
       "│    └─downsampleBlock: 2-4              [32, 128, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-28                 [32, 128, 56, 56]         8,320\n",
       "│    │    └─BatchNorm2d: 3-29            [32, 128, 56, 56]         256\n",
       "│    │    └─ReLU: 3-30                   [32, 128, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-31                 [32, 128, 56, 56]         147,584\n",
       "│    │    └─BatchNorm2d: 3-32            [32, 128, 56, 56]         256\n",
       "│    │    └─Conv2d: 3-33                 [32, 128, 56, 56]         8,320\n",
       "│    │    └─BatchNorm2d: 3-34            [32, 128, 56, 56]         256\n",
       "│    │    └─ReLU: 3-35                   [32, 128, 56, 56]         --\n",
       "├─Sequential: 1-5                        [32, 256, 28, 28]         --\n",
       "│    └─ResBlock128: 2-5                  [32, 128, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-36                 [32, 32, 56, 56]          4,128\n",
       "│    │    └─BatchNorm2d: 3-37            [32, 32, 56, 56]          64\n",
       "│    │    └─ReLU: 3-38                   [32, 32, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-39                 [32, 32, 56, 56]          9,248\n",
       "│    │    └─BatchNorm2d: 3-40            [32, 32, 56, 56]          64\n",
       "│    │    └─ReLU: 3-41                   [32, 32, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-42                 [32, 128, 56, 56]         4,224\n",
       "│    │    └─BatchNorm2d: 3-43            [32, 128, 56, 56]         256\n",
       "│    │    └─ReLU: 3-44                   [32, 128, 56, 56]         --\n",
       "│    └─ResBlock128: 2-6                  [32, 128, 56, 56]         (recursive)\n",
       "│    │    └─Conv2d: 3-45                 [32, 32, 56, 56]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-46            [32, 32, 56, 56]          (recursive)\n",
       "│    │    └─ReLU: 3-47                   [32, 32, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-48                 [32, 32, 56, 56]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-49            [32, 32, 56, 56]          (recursive)\n",
       "│    │    └─ReLU: 3-50                   [32, 32, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-51                 [32, 128, 56, 56]         (recursive)\n",
       "│    │    └─BatchNorm2d: 3-52            [32, 128, 56, 56]         (recursive)\n",
       "│    │    └─ReLU: 3-53                   [32, 128, 56, 56]         --\n",
       "│    └─ResBlock128: 2-7                  [32, 128, 56, 56]         (recursive)\n",
       "│    │    └─Conv2d: 3-54                 [32, 32, 56, 56]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-55            [32, 32, 56, 56]          (recursive)\n",
       "│    │    └─ReLU: 3-56                   [32, 32, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-57                 [32, 32, 56, 56]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-58            [32, 32, 56, 56]          (recursive)\n",
       "│    │    └─ReLU: 3-59                   [32, 32, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-60                 [32, 128, 56, 56]         (recursive)\n",
       "│    │    └─BatchNorm2d: 3-61            [32, 128, 56, 56]         (recursive)\n",
       "│    │    └─ReLU: 3-62                   [32, 128, 56, 56]         --\n",
       "│    └─downsampleBlock: 2-8              [32, 256, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-63                 [32, 256, 28, 28]         33,024\n",
       "│    │    └─BatchNorm2d: 3-64            [32, 256, 28, 28]         512\n",
       "│    │    └─ReLU: 3-65                   [32, 256, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-66                 [32, 256, 28, 28]         590,080\n",
       "│    │    └─BatchNorm2d: 3-67            [32, 256, 28, 28]         512\n",
       "│    │    └─Conv2d: 3-68                 [32, 256, 28, 28]         33,024\n",
       "│    │    └─BatchNorm2d: 3-69            [32, 256, 28, 28]         512\n",
       "│    │    └─ReLU: 3-70                   [32, 256, 28, 28]         --\n",
       "├─Sequential: 1-6                        [32, 512, 14, 14]         --\n",
       "│    └─ResBlock256: 2-9                  [32, 256, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-71                 [32, 64, 28, 28]          16,448\n",
       "│    │    └─BatchNorm2d: 3-72            [32, 64, 28, 28]          128\n",
       "│    │    └─ReLU: 3-73                   [32, 64, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-74                 [32, 64, 28, 28]          36,928\n",
       "│    │    └─BatchNorm2d: 3-75            [32, 64, 28, 28]          128\n",
       "│    │    └─ReLU: 3-76                   [32, 64, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-77                 [32, 256, 28, 28]         16,640\n",
       "│    │    └─BatchNorm2d: 3-78            [32, 256, 28, 28]         512\n",
       "│    │    └─ReLU: 3-79                   [32, 256, 28, 28]         --\n",
       "│    └─ResBlock256: 2-10                 [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─Conv2d: 3-80                 [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-81            [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─ReLU: 3-82                   [32, 64, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-83                 [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-84            [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─ReLU: 3-85                   [32, 64, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-86                 [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─BatchNorm2d: 3-87            [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─ReLU: 3-88                   [32, 256, 28, 28]         --\n",
       "│    └─ResBlock256: 2-11                 [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─Conv2d: 3-89                 [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-90            [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─ReLU: 3-91                   [32, 64, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-92                 [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-93            [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─ReLU: 3-94                   [32, 64, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-95                 [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─BatchNorm2d: 3-96            [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─ReLU: 3-97                   [32, 256, 28, 28]         --\n",
       "│    └─ResBlock256: 2-12                 [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─Conv2d: 3-98                 [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-99            [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─ReLU: 3-100                  [32, 64, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-101                [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-102           [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─ReLU: 3-103                  [32, 64, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-104                [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─BatchNorm2d: 3-105           [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─ReLU: 3-106                  [32, 256, 28, 28]         --\n",
       "│    └─ResBlock256: 2-13                 [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─Conv2d: 3-107                [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-108           [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─ReLU: 3-109                  [32, 64, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-110                [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-111           [32, 64, 28, 28]          (recursive)\n",
       "│    │    └─ReLU: 3-112                  [32, 64, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-113                [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─BatchNorm2d: 3-114           [32, 256, 28, 28]         (recursive)\n",
       "│    │    └─ReLU: 3-115                  [32, 256, 28, 28]         --\n",
       "│    └─downsampleBlock: 2-14             [32, 512, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-116                [32, 512, 14, 14]         131,584\n",
       "│    │    └─BatchNorm2d: 3-117           [32, 512, 14, 14]         1,024\n",
       "│    │    └─ReLU: 3-118                  [32, 512, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-119                [32, 512, 14, 14]         2,359,808\n",
       "│    │    └─BatchNorm2d: 3-120           [32, 512, 14, 14]         1,024\n",
       "│    │    └─Conv2d: 3-121                [32, 512, 14, 14]         131,584\n",
       "│    │    └─BatchNorm2d: 3-122           [32, 512, 14, 14]         1,024\n",
       "│    │    └─ReLU: 3-123                  [32, 512, 14, 14]         --\n",
       "├─Sequential: 1-7                        [32, 512, 14, 14]         --\n",
       "│    └─ResBlock512: 2-15                 [32, 512, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-124                [32, 128, 14, 14]         65,664\n",
       "│    │    └─BatchNorm2d: 3-125           [32, 128, 14, 14]         256\n",
       "│    │    └─ReLU: 3-126                  [32, 128, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-127                [32, 128, 14, 14]         147,584\n",
       "│    │    └─BatchNorm2d: 3-128           [32, 128, 14, 14]         256\n",
       "│    │    └─ReLU: 3-129                  [32, 128, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-130                [32, 512, 14, 14]         66,048\n",
       "│    │    └─BatchNorm2d: 3-131           [32, 512, 14, 14]         1,024\n",
       "│    │    └─ReLU: 3-132                  [32, 512, 14, 14]         --\n",
       "│    └─ResBlock512: 2-16                 [32, 512, 14, 14]         (recursive)\n",
       "│    │    └─Conv2d: 3-133                [32, 128, 14, 14]         (recursive)\n",
       "│    │    └─BatchNorm2d: 3-134           [32, 128, 14, 14]         (recursive)\n",
       "│    │    └─ReLU: 3-135                  [32, 128, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-136                [32, 128, 14, 14]         (recursive)\n",
       "│    │    └─BatchNorm2d: 3-137           [32, 128, 14, 14]         (recursive)\n",
       "│    │    └─ReLU: 3-138                  [32, 128, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-139                [32, 512, 14, 14]         (recursive)\n",
       "│    │    └─BatchNorm2d: 3-140           [32, 512, 14, 14]         (recursive)\n",
       "│    │    └─ReLU: 3-141                  [32, 512, 14, 14]         --\n",
       "├─Linear: 1-8                            [32, 128]                 65,664\n",
       "├─BatchNorm1d: 1-9                       [32, 128]                 256\n",
       "├─ReLU: 1-10                             [32, 128]                 --\n",
       "├─Linear: 1-11                           [32, 2]                   258\n",
       "├─Sigmoid: 1-12                          [32, 2]                   --\n",
       "├─Linear: 1-13                           [32, 2]                   258\n",
       "├─Sigmoid: 1-14                          [32, 2]                   --\n",
       "├─Linear: 1-15                           [32, 2]                   258\n",
       "├─Sigmoid: 1-16                          [32, 2]                   --\n",
       "├─Linear: 1-17                           [32, 2]                   258\n",
       "├─Sigmoid: 1-18                          [32, 2]                   --\n",
       "├─Linear: 1-19                           [32, 2]                   258\n",
       "├─Sigmoid: 1-20                          [32, 2]                   --\n",
       "├─Linear: 1-21                           [32, 2]                   258\n",
       "├─Sigmoid: 1-22                          [32, 2]                   --\n",
       "├─Linear: 1-23                           [32, 2]                   258\n",
       "├─Sigmoid: 1-24                          [32, 2]                   --\n",
       "├─Linear: 1-25                           [32, 2]                   258\n",
       "├─Sigmoid: 1-26                          [32, 2]                   --\n",
       "├─Linear: 1-27                           [32, 2]                   258\n",
       "├─Sigmoid: 1-28                          [32, 2]                   --\n",
       "├─Linear: 1-29                           [32, 2]                   258\n",
       "├─Sigmoid: 1-30                          [32, 2]                   --\n",
       "├─Linear: 1-31                           [32, 2]                   258\n",
       "├─Sigmoid: 1-32                          [32, 2]                   --\n",
       "├─Linear: 1-33                           [32, 2]                   258\n",
       "├─Sigmoid: 1-34                          [32, 2]                   --\n",
       "==========================================================================================\n",
       "Total params: 3,910,488\n",
       "Trainable params: 3,910,488\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 113.58\n",
       "==========================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3262.72\n",
       "Params size (MB): 15.64\n",
       "Estimated Total Size (MB): 3297.63\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_c = ResNet(batch_size = 32)\n",
    "summary(res_c, input_size = (32,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 224, 224])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets get a batch of data and try to our model into our data.\n",
    "exp_train_data, exp_train_label = [],[]\n",
    "\n",
    "for i in range(32):\n",
    "    img, labels,_ = train_coco[i]\n",
    "    exp_train_data.append(img)\n",
    "    exp_train_label.append(labels)\n",
    "# exp_train_data = torch.tensor(exp_train_data)\n",
    "# exp_train_label = torch.tensor(exp_train_label)\n",
    "# print(exp_train_data.shape)\n",
    "# print(exp_train_label.shape)\n",
    "# print(len(exp_train_data), len(exp_train_label))\n",
    "exp_train_data = torch.stack(exp_train_data)\n",
    "exp_train_label = torch.stack(exp_train_label)\n",
    "exp_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_train_data = exp_train_data.to(device=device)\n",
    "exp_train_label = exp_train_label.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 224, 224])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 4.00 GiB total capacity; 2.82 GiB already allocated; 0 bytes free; 2.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m res_c \u001b[39m=\u001b[39m res_c\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m----> 2\u001b[0m res_c(exp_train_data)\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[14], line 83\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     80\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresblocks128(out)\n\u001b[0;32m     82\u001b[0m \u001b[39m# output after resblock256\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresblocks256(out)\n\u001b[0;32m     85\u001b[0m \u001b[39m# output after resblock 512\u001b[39;00m\n\u001b[0;32m     86\u001b[0m out \u001b[39m=\u001b[39m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresblocks512(out)\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[13], line 104\u001b[0m, in \u001b[0;36mResBlock256.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    102\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out)))\n\u001b[0;32m    103\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(out))\n\u001b[1;32m--> 104\u001b[0m out_final \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu3(out \u001b[39m+\u001b[39;49m x)\n\u001b[0;32m    105\u001b[0m \u001b[39mreturn\u001b[39;00m out_final\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py:102\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 102\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\Anant\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[0;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 4.00 GiB total capacity; 2.82 GiB already allocated; 0 bytes free; 2.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "res_c = res_c.to(device=device)\n",
    "res_c(exp_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5863a01bb4350d9241febf9e57f76b3c44dc4260331656e165259b66bc149002"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
